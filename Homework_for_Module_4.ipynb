{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+Wvg9ZdcFZdVcp4kW4Ft8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MCn21thCntry/Practical-Machine-Learning---from-the-rooter-to-the-tooter/blob/main/Homework_for_Module_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Homework for Module 4: Model Validation and EvaluationÂ¶\n",
        "\n",
        "Instructions:\n",
        "\n",
        "This homework is designed to reinforce the concepts and techniques covered in Module 4. Please submit your answers and code (if applicable) in a Colab notebook.\n",
        "\n",
        "https://www.kaggle.com/code/khaledhijja/module-4-ml-validation-and-evaluation"
      ],
      "metadata": {
        "id": "A1i6h6_kRaoE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Regression Model Validation - Predicting Lot Area\n",
        "\n",
        "For this part, we will use the same Iowa housing dataset, but this time, we will try to predict the LotArea (Lot size in square feet) of houses using a Decision Tree Regressor."
      ],
      "metadata": {
        "id": "B-0tvhK9RdDi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Prepare Data:\n",
        "\n",
        "  * Load the Iowa dataset as you did in the module.\n",
        "  * Select LotArea as the target variable (y).\n",
        "  * Use the same numeric features (X) you used in the module (excluding 'SalePrice' and now also 'LotArea' if it's included, but it shouldn't be if you followed the module steps correctly).\n",
        "  * Split the data into training and validation sets using train_test_split with test_size=0.2 and random_state=0."
      ],
      "metadata": {
        "id": "6hltzh5L9dDn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "QF0KoDUeRPpN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f503215-a981-431e-ea5c-2f2f763a5d3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-56df99624ae4>:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  iowa_data[col].fillna(iowa_data[col].mean(), inplace=True)\n",
            "<ipython-input-30-56df99624ae4>:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  iowa_data[col].fillna(iowa_data[col].mode()[0], inplace=True)\n"
          ]
        }
      ],
      "source": [
        "## Reach the data in your drive\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Load the Iowa dataset as you did in the module.\n",
        "# Load data from a CSV file in your Drive\n",
        "iowa_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Iowa Housing Dataset/train.csv')\n",
        "iowa_data.head()\n",
        "\n",
        "## Handle missing values\n",
        "for col in iowa_data.columns:\n",
        "  if iowa_data[col].isna().sum() > 0:\n",
        "    if iowa_data[col].dtype == 'object':\n",
        "      iowa_data[col].fillna(iowa_data[col].mode()[0], inplace=True)\n",
        "    else:\n",
        "      iowa_data[col].fillna(iowa_data[col].mean(), inplace=True)\n",
        "\n",
        "## handle the categorical features otherwiese they can cause errors during the model generation\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "# Get the columns with 'object' data type.\n",
        "object_columns = iowa_data.select_dtypes(include=['object']).columns # 43\n",
        "for col in iowa_data.select_dtypes(include=[\"object\"]).columns:\n",
        "  ## Drop categoric features having only 1 class\n",
        "  if iowa_data[col].nunique() < 2:\n",
        "    iowa_data.drop(col, axis=1, inplace=True)\n",
        "  ## Label encoding for feautures with 2 classses\n",
        "  elif iowa_data[col].nunique() == 2:\n",
        "    label_encoder = LabelEncoder()\n",
        "    iowa_data[col] = label_encoder.fit_transform(iowa_data[col])\n",
        "  ## One-hot encoding for features with more than 2 classes\n",
        "  else:\n",
        "    one_hot_encoder = OneHotEncoder(drop=\"first\", max_categories=10, handle_unknown='infrequent_if_exist', min_frequency=0.01, sparse_output=False)\n",
        "    iowa_data[col] = one_hot_encoder.fit_transform(iowa_data[[col]])\n",
        "\n",
        "# Select LotArea as the target variable (y).\n",
        "y = iowa_data['Lot Area']\n",
        "# Use the same numeric features (X) you used in the module (excluding 'SalePrice' and now also 'LotArea' if it's included, but it shouldn't be if you followed the module steps correctly).\n",
        "X = iowa_data.drop(['SalePrice', 'Lot Area'], axis=1)\n",
        "\n",
        "# Split the data into training and validation sets using train_test_split with test_size=0.2 and random_state=0.\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Train and Evaluate a Decision Tree Regressor:\n",
        "\n",
        "  * Train a DecisionTreeRegressor model (with random_state=0) on the training data (X_train, y_train).\n",
        "  * Make predictions on the validation set (X_val).\n",
        "  * Calculate the Mean Absolute Error (MAE) and Mean Squared * Error (MSE) on the validation set.\n",
        "  * Print the MAE and MSE values."
      ],
      "metadata": {
        "id": "DJe-Jiqg9nA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a DecisionTreeRegressor model (with random_state=0) on the training data (X_train, y_train).\n",
        "tree_model = DecisionTreeRegressor(random_state=0)\n",
        "tree_model.fit(X_train, y_train)\n",
        "# Make predictions on the validation set (X_val).\n",
        "predictions = tree_model.predict(X_val)\n",
        "\n",
        "# Calculate the Mean Absolute Error (MAE) and Mean Squared * Error (MSE) on the validation set.\n",
        "mae = mean_absolute_error(y_val, predictions)\n",
        "mse = mean_squared_error(y_val, predictions)\n",
        "\n",
        "# Print the MAE and MSE values.\n",
        "print(\"After handling missing: Mean Absolute Error (MAE):\", mae) # before handling missing: 4085.6704545454545\n",
        "print(\"After handling missing: Mean Squared Error (MSE):\", mse) # before handling missing: 272882503.37045455\n",
        "y_val.describe()"
      ],
      "metadata": {
        "id": "95ERarQi9ncq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "82f5b092-de46-4040-db1b-e12dd513f482"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After handling missing: Mean Absolute Error (MAE): 3167.1295454545457\n",
            "After handling missing: Mean Squared Error (MSE): 129027281.65227273\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count       440.000000\n",
              "mean      10089.527273\n",
              "std        7061.013771\n",
              "min        1476.000000\n",
              "25%        7221.250000\n",
              "50%        9372.500000\n",
              "75%       11645.000000\n",
              "max      115149.000000\n",
              "Name: Lot Area, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Lot Area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>440.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10089.527273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7061.013771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1476.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7221.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9372.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>11645.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>115149.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Hyperparameter Tuning for Decision Tree:\n",
        "  * Experiment with different values of the max_leaf_nodes hyperparameter for the DecisionTreeRegressor. Try at least 3 different values (e.g., 10, 100, 1000).\n",
        "  * For each max_leaf_nodes value, train a new Decision Tree model and calculate the MAE on the validation set.\n",
        "  * Record the MAE for each max_leaf_nodes value.\n",
        "  * Which max_leaf_nodes value gives the lowest MAE on the validation set?"
      ],
      "metadata": {
        "id": "glfimM249oZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment with different values of the max_leaf_nodes hyperparameter for the DecisionTreeRegressor. Try at least 3 different values (e.g., 10, 100, 1000).\n",
        "max_leaf_nodes_values = [10, 100, 1000]\n",
        "\n",
        "# For each max_leaf_nodes value, train a new Decision Tree model and calculate the MAE on the validation set.\n",
        "mae_list = []\n",
        "for max_leaf_nodes in max_leaf_nodes_values:\n",
        "    tree_model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
        "    tree_model.fit(X_train, y_train)\n",
        "    predictions = tree_model.predict(X_val)\n",
        "    mae = mean_absolute_error(y_val, predictions)\n",
        "    # Record the MAE for each max\n",
        "    mae_list.append(mae)\n",
        "# Which max_leaf_nodes value gives the lowest MAE on the validation set?\n",
        "best_max_leaf_nodes = max_leaf_nodes_values[np.argmin(mae_list)]\n",
        "print(\"After handling missing:: Best max_leaf_nodes value:\", best_max_leaf_nodes) # before handling missing: 100"
      ],
      "metadata": {
        "id": "Cz_riN-X9pJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "864d91c4-9cf0-47e4-d410-1ad0ae238961"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After handling missing:: Best max_leaf_nodes value: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Analysis (Written Answers):\n",
        "\n",
        "  * Report the MAE and MSE values for the Decision Tree model (without hyperparameter tuning). What do these metrics tell you about the model's performance in predicting Lot Area?\n",
        "    * MSE value looks so huge and MAE value looks good when we compare them with std and mean of y_val. These two metrics say that model performance is not perfect but good to take into account and use the model for new/unseen data so it is reliable to use for further.\n",
        "  * Which max_leaf_nodes value (from your experiments) resulted in the lowest validation MAE? How did changing max_leaf_nodes affect the MAE?\n",
        "    * 100 max_leaf_nodes value resulted in the lowest validation MAE. Number of max_leaf_nodes refers to the number of braches so it is related to splitting of features and it means that diversity and generalization the model includes. Providing these possessings, changing max_leaf_nodes affected the MAE.\n",
        "  * Based on your experiments, what would be your chosen Decision Tree model (with what max_leaf_nodes value) for predicting Lot Area? Justify your choice.\n",
        "    * I exactly would choose 100 max_leaf_nodes for predicting Lot Area because it makes the result the most successful as we saw in the example and compatible with the number of observations and features in terms of providing this kind of diversities."
      ],
      "metadata": {
        "id": "6oz6csb19p9n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Classification Model Validation - Predicting Above Average Lot Area\n",
        "\n",
        "Now, let's switch to a classification task. We will try to predict whether a house has an \"Above Average Lot Area\" or \"Below Average Lot Area\"."
      ],
      "metadata": {
        "id": "73-S9URqRZ-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Create a Binary Target Variable:\n",
        "\n",
        "  * Calculate the median LotArea from the training set (y_train from Part 1).\n",
        "  * Create a binary target variable y_binary_train_lot and y_binary_val_lot:\n",
        "      * If a house's LotArea is above the median, set the binary target to 1 (for \"Above Average\").\n",
        "      * Otherwise, set it to 0 (for \"Below Average\")."
      ],
      "metadata": {
        "id": "kJE1wI6lCMR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the median LotArea from the training set (y_train from Part 1).\n",
        "median_lot_area = y_train.median()\n",
        "\n",
        "# Create a binary target variable y_binary_train_lot and y_binary_val_lot:\n",
        "# If a house's LotArea is above the median, set the binary target to 1 (for \"Above Average\").\n",
        "# Otherwise, set it to 0 (for \"Below Average\").\n",
        "y_binary_train_lot = (y_train > median_lot_area).astype(int)\n",
        "y_binary_val_lot = (y_val > median_lot_area).astype(int)\n",
        "\"\"\"\n",
        "(y_train > median_lot_area) creates a boolean Series where True indicates values above the median.\n",
        "astype(int) converts the boolean values to integers (0 and 1).\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YsWGtkhgTM8G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1e56ba9f-0cdf-48ea-a896-dcb10ad2f153"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n(y_train > median_lot_area) creates a boolean Series where True indicates values above the median.\\nastype(int) converts the boolean values to integers (0 and 1).\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Train and Evaluate a Decision Tree Classifier:\n",
        "  * Train a DecisionTreeClassifier model (with random_state=0) on the training data (X_train, y_binary_train_lot).\n",
        "  * Make predictions on the validation set (X_val).\n",
        "  * Calculate the following classification metrics on the validation set:\n",
        "      * Accuracy\n",
        "      * Precision\n",
        "      * Recall\n",
        "      * Specificity\n",
        "      * Confusion Matrix (display the matrix)\n",
        "  * Print all the calculated metrics and display the confusion matrix."
      ],
      "metadata": {
        "id": "t8QDZU_FCNFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a DecisionTreeClassifier model (with random_state=0) on the training data (X_train, y_binary_train_lot).\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree_model = DecisionTreeClassifier(random_state=0)\n",
        "tree_model.fit(X_train, y_binary_train_lot)\n",
        "\n",
        "# Make predictions on the validation set (X_val).\n",
        "predictions = tree_model.predict(X_val)\n",
        "\n",
        "# Calculate the following classification metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "accuracy = accuracy_score(y_binary_val_lot, predictions)\n",
        "precision = precision_score(y_binary_val_lot, predictions)\n",
        "recall = recall_score(y_binary_val_lot, predictions)\n",
        "\n",
        "confusion = confusion_matrix(y_binary_val_lot, predictions)\n",
        "# Calculate specificity\n",
        "tn, fp, fn, tp = confusion.ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "\n",
        "# Print all the calculated metrics and display the confusion matrix.\n",
        "print(\"Accuracy:\", accuracy) # before handling missing: 0.6977272727272728\n",
        "print(\"Precision:\", precision) # 0.6742081447963801\n",
        "print(\"Recall:\", recall) # 0.7095238095238096\n",
        "print(\"Specificity:\", specificity) # 0.6869565217391305\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion) # [[158  72] [ 61 149]]\n",
        "print(tn, fp, fn, tp)"
      ],
      "metadata": {
        "id": "UA65pyz1CNgS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c42cedaf-10c7-4efc-bf9e-6494051d92c6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7522727272727273\n",
            "Precision: 0.730593607305936\n",
            "Recall: 0.7619047619047619\n",
            "Specificity: 0.7434782608695653\n",
            "Confusion Matrix:\n",
            "[[171  59]\n",
            " [ 50 160]]\n",
            "171 59 50 160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Analysis (Written Answers):\n",
        "  * Analyze the classification metrics you calculated for the Decision Tree Classifier. How would you describe the performance of the classifier in predicting \"Above Average Lot Area\"?\n",
        "    * All the metrics are nearly in the same range and so close to each other and they are successful results. It demonstrates that the model designed with well-balanced.\n",
        "  * Examine the Confusion Matrix. Are there more False Positives or False Negatives? What does this tell you about the types of errors the classifier is making?\n",
        "    * False Positives are more than False Negatives. I tells me lower than average predictions in Lot Area above average are more than higher than average in Lot Area below average.\n",
        "  * In the context of predicting \"Above Average Lot Area,\" if you wanted to prioritize minimizing False Positives (i.e., be very sure when you predict \"Above Average\"), which metric would you focus on, and why?\n",
        "    * Exactly I would focus on precision metric because it is based on investigation of False Positives rate prediction, which means that if precision is high False Positives rate are low otherwise hig."
      ],
      "metadata": {
        "id": "jfssBAboCNzu"
      }
    }
  ]
}