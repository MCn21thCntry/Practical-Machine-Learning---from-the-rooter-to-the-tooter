{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "name": "Module 6 Random Forests",
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 260251,
          "sourceType": "datasetVersion",
          "datasetId": 108980
        }
      ],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MCn21thCntry/Practical-Machine-Learning---from-the-rooter-to-the-tooter/blob/main/Module_6_Random_Forests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "dansbecker_home_data_for_ml_course_path = kagglehub.dataset_download('dansbecker/home-data-for-ml-course')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "GikMwb83Zd1L"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Module 6: Ensemble Methods: Decision Trees, Bagging, Pasting, and Random Forests - A Deep Dive for Practical Machine Learning\n",
        "\n",
        "**Welcome to Module 6!** This module offers a comprehensive exploration of Ensemble Methods in Machine Learning, focusing on the practical implementation and comparative analysis of Decision Trees, Bagging, Pasting, and Random Forests. We will systematically build our understanding, starting from the fundamental Decision Tree algorithm and progressing to more sophisticated ensemble techniques.\n",
        "\n",
        "**Module Objectives:**\n",
        "\n",
        "By the end of this module, you will be able to:\n",
        "\n",
        "1.  **Understand Ensemble Learning:**  Grasp the core concept of ensemble learning and its advantages in improving model performance and robustness.\n",
        "2.  **Implement Decision Tree Baselines:**  Create and evaluate single Decision Tree Regressor and Classifier models as baseline references for performance comparison.\n",
        "3.  **Master Bagging and Pasting:** Implement and analyze Bagging and Pasting ensembles for both regression and classification tasks, understanding their sampling methodologies and performance characteristics.\n",
        "4.  **Explore Random Forests:**  Delve into Random Forests, understanding their unique combination of Bagging and feature randomness, and implement them for regression and classification.\n",
        "5.  **Tune Random Forest Hyperparameters:**  Learn how to tune key hyperparameters of Random Forests, such as `n_estimators` and `max_depth`, to optimize model performance.\n",
        "6.  **Compare Ensemble Methods:**  Systematically compare the performance of Decision Trees, Bagging, Pasting, and Random Forests across regression and classification tasks, using appropriate evaluation metrics and visualizations.\n",
        "7.  **Analyze Feature Importance:**  Utilize Random Forests to gain insights into feature importance and understand the relevance of different features in predictive modeling.\n",
        "8.  **Evaluate Pros and Cons:**  Critically assess the advantages and disadvantages of ensemble methods, considering factors like accuracy, interpretability, computational cost, and complexity.\n",
        "9.  **Appreciate Advanced Ensemble Concepts:**  Gain a foundational awareness of more advanced ensemble techniques like Boosting and Stacking, and explore future directions in ensemble learning research.\n",
        "\n",
        "**Module Structure:**\n",
        "\n",
        "This module is structured in a step-by-step manner, progressing from simpler to more complex concepts and models:\n",
        "\n",
        "*   **Introduction to Ensemble Learning:** Setting the stage for why combining models is powerful.\n",
        "*   **Step 0: Decision Tree Baselines:** Establishing performance benchmarks using single Decision Tree Regressors and Classifiers.\n",
        "*   **Step 1: Bagging Ensembles:** Exploring Bagging for both Regression and Classification, and comparing performance to baselines.\n",
        "*   **Step 2: Pasting Ensembles:** Investigating Pasting for Regression and Classification, comparing performance to baselines and Bagging.\n",
        "*   **Step 3: Random Forest Ensembles:** Implementing and evaluating Random Forests for Regression and Classification, comparing performance to baselines, Bagging, and Pasting.\n",
        "*   **Step 4: Hyperparameter Tuning for Random Forests:**  Learning to tune `n_estimators` and `max_depth` to optimize Random Forest models, with visual analysis of tuning effects.\n",
        "*   **Step 5: Comprehensive Model Performance Comparison:**  A direct, side-by-side comparison of all models across both regression and classification tasks, using tables and plots to visualize performance differences.\n",
        "*   **Step 6: Unveiling Feature Importance in Random Forests:**  Exploring and visualizing feature importances to understand model insights and data characteristics.\n",
        "*   **Step 7: Critical Evaluation: Pros and Cons of Ensemble Methods:**  Discussing the strengths and limitations of ensemble methods in practical scenarios.\n",
        "*   **Step 8: Expanding Horizons: Advanced Techniques and Future Directions:**  Briefly introducing more advanced ensemble methods and emerging research areas.\n",
        "*   **Step 9: Conclusion and Summary:**  Recap of key learnings and preparation for the next module.\n",
        "\n",
        "Let's begin our journey into the world of Ensemble Methods, starting with Decision Tree baselines!\n"
      ],
      "metadata": {
        "id": "6wMdhuMjYb6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble Learning: A Detailed Overview\n",
        "\n",
        "Ensemble learning is a powerful machine learning technique that combines the predictions of multiple individual models (often called \"base learners\" or \"weak learners\") to produce a more accurate and robust prediction than any single model could achieve alone.  Think of it as leveraging the **\"wisdom of the crowd\"** in the realm of machine learning.  Instead of relying on a single expert, we consult a diverse group of experts and aggregate their opinions to make a better decision.\n",
        "\n",
        "**In detail, Ensemble Learning works by:**\n",
        "\n",
        "1.  **Training Multiple Base Learners:**  Creating a set of diverse individual models. This diversity is crucial and can be achieved through various methods such as:\n",
        "    *   **Different Algorithms:** Using different types of machine learning algorithms (e.g., Decision Trees, Linear Regression, Neural Networks) as base learners.\n",
        "    *   **Different Training Data Subsets:**  Training each base learner on a different subset of the original training data (e.g., Bagging, Pasting).\n",
        "    *   **Different Feature Subsets:**  Training each base learner on a different subset of the features (e.g., Random Subspace).\n",
        "    *   **Different Initializations:** For algorithms sensitive to initial conditions (like Neural Networks), using different random initializations.\n",
        "\n",
        "2.  **Combining Predictions:**  Developing a strategy to aggregate the predictions of all the base learners. Common aggregation methods include:\n",
        "    *   **Voting (for Classification):**  Each base learner \"votes\" for a class, and the class with the majority vote is the final prediction.  Can be *hard voting* (majority class) or *soft voting* (average predicted probabilities).\n",
        "    *   **Averaging (for Regression):**  Simply averaging the predictions of all base learners.\n",
        "    *   **Weighted Averaging:**  Assigning weights to each base learner based on its performance and then calculating a weighted average of predictions.\n",
        "    *   **Stacking (Stacked Generalization):** Training a \"meta-learner\" on the predictions of the base learners to learn the optimal way to combine them.\n",
        "\n",
        "**When to Use Ensemble Learning:**\n",
        "\n",
        "Ensemble learning is particularly beneficial and often recommended in the following situations:\n",
        "\n",
        "*   **High Accuracy is Critical:** When you need to achieve the highest possible predictive accuracy, ensemble methods often outperform single models, especially for complex problems.\n",
        "*   **Reducing Overfitting:**  Ensembles, particularly methods like Random Forests and Boosting, are effective at reducing overfitting and improving generalization to unseen data.\n",
        "*   **Handling Complex Datasets:**  When dealing with datasets that are high-dimensional, noisy, or have complex relationships between features and the target variable, ensembles can capture more intricate patterns.\n",
        "*   **Robustness and Stability:** Ensembles are generally more robust to noise and outliers in the data compared to single models, as errors from individual learners tend to cancel each other out.\n",
        "*   **Competitive Machine Learning:** In many machine learning competitions, ensemble methods are frequently used to achieve top rankings due to their superior performance.\n",
        "*   **Better Generalization:** Ensembles tend to generalize better to unseen data because they average out the errors of individual models, leading to more consistent performance\n",
        "\n",
        "**Pros and Cons of Ensemble Learning:**\n",
        "\n",
        "| **Pros**                                  | **Cons**                                      |\n",
        "|-------------------------------------------|-----------------------------------------------|\n",
        "| **Higher Accuracy:** Often achieves better predictive performance than single models. | **Increased Complexity:** Ensembles are generally more complex to understand and implement than single models. |\n",
        "| **Improved Robustness:** More stable and less sensitive to noisy data or outliers. | **Higher Computational Cost:** Training and prediction can be more computationally expensive, especially for large ensembles or complex base learners. |\n",
        "| **Better Generalization:** Reduces overfitting and improves performance on unseen data. | **Reduced Interpretability:** Ensembles can be \"black boxes,\" making it harder to understand *why* a particular prediction is made compared to simpler models (though feature importance techniques can help). |\n",
        "| **Versatility:** Can be applied to various types of data and machine learning tasks (classification, regression, etc.). | **Potential for Over-Engineering:**  Careful tuning and selection of base learners and combination methods are needed to avoid unnecessary complexity or decreased performance. |\n",
        "| **Reduced Variance and Bias:**  Addresses both types of errors in machine learning models. | **Requires More Data (sometimes):**  Some ensemble methods might benefit from larger datasets to train diverse and effective base learners. |\n",
        "\n",
        "**Table of Ensemble Models:**\n",
        "\n",
        "| Ensemble Model         | Description                                                                      | Pros                                                                                                                               | Cons                                                                                                                              |\n",
        "|--------------------------|----------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------|\n",
        "| **Bagging (Bootstrap Aggregating)** | Trains multiple instances of the same base learner on bootstrapped subsets of the training data and averages their predictions. | Simple to implement, reduces variance significantly, improves stability and robustness, parallelizable training.                         | Can slightly increase bias if base learners are already very complex, may not significantly improve performance if base learners are already strong. |\n",
        "| **Pasting**              | Similar to Bagging, but samples are drawn without replacement.                      | Less randomness than Bagging, can sometimes outperform Bagging, potentially faster training in some cases.                         | May not reduce variance as effectively as Bagging, can still be sensitive to overfitting if base learners are complex.               |\n",
        "| **Random Forests**        | An extension of Bagging that introduces further randomness by also selecting random subsets of features at each node split in decision trees. | Very high accuracy, robust to outliers and noise, reduces variance and overfitting effectively, provides feature importance estimates. | Less interpretable than single decision trees, can be computationally expensive for very large datasets or many trees, hyperparameter tuning can be important. |\n",
        "| **Boosting (Adaptive Boosting - AdaBoost)** | Sequentially trains base learners, where each learner attempts to correct the mistakes of its predecessors. Weights are adjusted to focus on misclassified instances. | High accuracy, effective at reducing bias and variance, relatively simple to implement, can work well with weak learners.     | Sensitive to noisy data and outliers, can overfit if base learners are too complex or training data is too small, can be slow for very large datasets. |\n",
        "| **Gradient Boosting Machines (GBM)** | Similar to AdaBoost but uses gradient descent to minimize a loss function in a stage-wise additive manner. Typically uses decision trees as base learners. | Very high accuracy, flexible loss functions, effective at handling complex relationships, robust to outliers and missing data (to some extent). | Can be prone to overfitting if not tuned properly, computationally intensive to train and tune, hyperparameter tuning is crucial. |\n",
        "| **XGBoost (Extreme Gradient Boosting)** | An optimized and highly efficient implementation of Gradient Boosting, with regularization and parallel processing capabilities. | State-of-the-art performance, very fast and efficient, regularized to prevent overfitting, handles missing data well, feature importance. | More complex to understand and tune than simpler ensembles, can still overfit if not carefully tuned, requires careful hyperparameter optimization. |\n",
        "| **LightGBM (Light Gradient Boosting Machine)** | Another highly efficient Gradient Boosting framework that uses tree-based learning algorithms and optimized techniques for speed and memory efficiency. | Very fast and efficient, lower memory consumption, high accuracy, handles large datasets well, supports categorical features directly.   | Can be more sensitive to overfitting with small datasets compared to XGBoost, hyperparameter tuning is still important for optimal performance. |\n",
        "| **CatBoost (Categorical Boosting)** | A Gradient Boosting algorithm that excels at handling categorical features directly and robustly, without extensive preprocessing. | Excellent at handling categorical features natively, robust and accurate, good out-of-the-box performance, feature importance.     | Can be slower than LightGBM or XGBoost in some cases, may require more computational resources for very large datasets, hyperparameter tuning can still be beneficial. |\n",
        "| **Stacking (Stacked Generalization)** | Trains a meta-learner to combine the predictions of diverse base learners. The meta-learner learns the optimal way to weight or combine the base learner predictions. | Can achieve very high accuracy by leveraging the strengths of different base learners, flexible in terms of base learners and meta-learner choice. | More complex to implement and tune than simpler ensembles, prone to overfitting if the meta-learner is too complex or training data is insufficient, computationally expensive. |\n",
        "\n",
        "**Bagging (Bootstrap Sampling):**\n",
        "\n",
        "Bagging uses bootstrap sampling, which means it draws samples from the original training data with replacement.\n",
        "\n",
        "With replacement means that when a data point is selected for a subset, it's put back into the original dataset, so it has a chance of being selected again for the same subset or other subsets.\n",
        "This results in subsets that are the same size as the original training data but contain some repeated data points and potentially leave out some data points in each subset.\n",
        "\n",
        "**Pasting (Sampling Without Replacement):**\n",
        "\n",
        "Pasting, on the other hand, draws samples from the original training data without replacement.\n",
        "\n",
        "Without replacement means that once a data point is selected for a subset, it's not put back into the original dataset. This prevents the same data point from appearing multiple times in the same subset.\n",
        "Each subset created in pasting contains unique data points from the training set, and generally each subset is smaller than the original training set.\n",
        "\n",
        "**Bootstrapped Subsets:** In machine learning, bootstrapping is a resampling technique used to create multiple subsets of data from a single original dataset. These subsets are called bootstrapped subsets or bootstrap samples.\n",
        "\n",
        "This overview provides a comprehensive understanding of ensemble learning, its benefits, drawbacks, and a range of popular ensemble models. Choosing the right ensemble method depends on the specific problem, dataset characteristics, and desired trade-off between accuracy, complexity, and computational cost."
      ],
      "metadata": {
        "id": "X0Ewv8hqKh_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Trees vs. Random Forests: Key Differences\n",
        "\n",
        "The fundamental difference between **Random Forests** and **Decision Trees** is that:\n",
        "\n",
        "*   **Decision Tree:** Employs a **single tree-like model**.\n",
        "* https://youtu.be/_L39rN6gz7Y?si=rFUeyJkguETXThx3\n",
        "*   **Random Forest:** Utilizes a **\"forest\" of many Decision Trees** working in concert.\n",
        "*https://youtu.be/J4Wdy0Wc_xQ?si=ZP_Q8TiTSdXbt5Xc\n",
        "\n",
        "Let's delve into a more detailed comparison:\n",
        "\n",
        "**1. Number of Models:**\n",
        "\n",
        "*   **Decision Tree:** Operates with **a solitary decision tree** to generate predictions, deriving a single set of rules from the training data.\n",
        "*   **Random Forest:** Comprises an **ensemble of multiple decision trees** (typically hundreds to thousands), collectively contributing to the final prediction.\n",
        "\n",
        "**2. Training Process and Data Utilization:**\n",
        "\n",
        "*   **Decision Tree:** Trained on the **entire training dataset**, aiming to construct a single, intricate tree that closely fits the training data.\n",
        "*   **Random Forest:** Each Decision Tree within a Random Forest is trained on a **distinct bootstrap sample** of the training data. **Bootstrap sampling** involves training each tree on a random subset of the original data, sampled *with replacement*. This process may result in some data points being repeated in a tree's training set, while others are excluded.\n",
        "\n",
        "**3. Feature Selection at Each Split:**\n",
        "\n",
        "*   **Decision Tree:** Considers **all available features** when determining node splits, seeking the optimal feature and split point to maximize information gain or minimize impurity.\n",
        "*   **Random Forest:** At each node split within each tree, only a **random subset of features** is considered. The algorithm randomly selects a few features and then identifies the best split among *those* selected features, introducing a key element of randomness beyond data sampling.\n",
        "\n",
        "**4. Overfitting Tendency:**\n",
        "\n",
        "*   **Decision Tree:** Exhibits a high **prone to overfitting**, particularly with deep trees. Single decision trees can memorize training data patterns too well, leading to poor generalization on new data.\n",
        "*   **Random Forest:** Significantly **reduces overfitting**. By averaging predictions from numerous trees trained on diverse data subsets and with feature randomness, Random Forests achieve greater robustness and better generalization.\n",
        "\n",
        "**5. Variance and Bias:**\n",
        "\n",
        "*   **Decision Tree:** Characterized by **low bias and high variance**. It can model complex relationships (low bias) but is highly sensitive to training data variations (high variance).\n",
        "*   **Random Forest:** Achieves **lower variance** than individual decision trees, while maintaining comparable or even lower bias. Bagging and feature randomness are key to variance reduction without increasing bias.\n",
        "\n",
        "**6. Performance (Accuracy/Generalization):**\n",
        "\n",
        "*   **Decision Tree:** Can perform adequately but is generally **less accurate and less robust** than Random Forests, especially on complex datasets or when generalization is critical.\n",
        "*   **Random Forest:** Known for being **more accurate and robust**, consistently outperforming single decision trees due to their ensemble nature and randomness.\n",
        "\n",
        "**7. Interpretability:**\n",
        "\n",
        "*   **Decision Tree:** **Highly interpretable**. Decision rules are easily visualized and understood by tracing tree paths.\n",
        "*   **Random Forest:** **Less interpretable** as a whole, acting more as a \"black box.\" However, they offer **feature importance** measures, providing some insight into feature influence.\n",
        "\n",
        "**8. Computational Cost:**\n",
        "\n",
        "*   **Decision Tree:** **Faster to train and predict** due to its simplicity as a single tree.\n",
        "*   **Random Forest:** **More computationally intensive** due to the training and aggregation of many trees. The performance gains, however, often justify the added cost.\n",
        "\n",
        "\n",
        "**Summary Table:**\n",
        "\n",
        "| Feature             | Decision Tree                                 | Random Forest                                      |\n",
        "|----------------------|-----------------------------------------------|----------------------------------------------------|\n",
        "| Number of Models    | One                                            | Many (Ensemble)                                   |\n",
        "| Training Data       | Entire training set                             | Bootstrap samples of training set                 |\n",
        "| Feature Selection   | All features considered at each split         | Random subset of features considered at each split |\n",
        "| Overfitting         | High tendency to overfit                        | Low tendency to overfit                           |\n",
        "| Variance            | High                                            | Low                                                |\n",
        "| Bias                | Low                                             | Low (similar to Decision Tree)                     |\n",
        "| Accuracy            | Lower                                           | Higher                                             |\n",
        "| Interpretability    | High                                            | Lower (but provides feature importance)             |\n",
        "| Computational Cost | Lower                                           | Higher                                             |\n",
        "\n",
        "**Use Cases:**\n",
        "\n",
        "*   **Decision Tree:** Ideal for scenarios prioritizing **interpretability** and simplicity, or when computational resources are limited.\n",
        "*   **Random Forest:** Preferred when **accuracy and robustness** are key, offering high performance and generalization, suitable as a go-to model for many ML problems despite higher computational demands."
      ],
      "metadata": {
        "id": "wB4h3Rh-MuK2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's clarify how **Decision Trees** and **Random Forests** handle training and validation data, as their approaches and purposes differ significantly due to their fundamental nature:\n",
        "\n",
        "**Decision Trees:**\n",
        "\n",
        "*   **Training Data:**\n",
        "    *   A single Decision Tree is trained using the **entire training dataset**.\n",
        "    *   The algorithm examines all features in the training data to determine the optimal splits at each node of the tree.\n",
        "    *   The goal during training is to build a tree structure that effectively learns the patterns and relationships within the training data to predict the target variable.\n",
        "    *   The training process continues until certain stopping criteria are met (e.g., maximum tree depth, minimum samples per leaf node, or perfect classification/regression on the training subset at a node).\n",
        "\n",
        "*   **Validation Data:**\n",
        "    *   Validation data is **not directly used during the training process** of a Decision Tree.\n",
        "    *   After the Decision Tree is fully trained on the training data, the **validation data is used to evaluate the model's performance on unseen data.**\n",
        "    *   This evaluation is crucial for:\n",
        "        *   **Assessing Generalization:** To estimate how well the trained Decision Tree will perform on new, data it has not encountered during training.\n",
        "        *   **Detecting Overfitting:**  If a Decision Tree performs very well on the training data but poorly on the validation data, it's a strong indication of overfitting. The tree has likely memorized the training data rather than learning generalizable patterns.\n",
        "        *   **Potentially for Pruning (though less common in basic examples):** In some advanced scenarios, validation data might be used to guide tree pruning techniques. Pruning aims to simplify the tree by removing branches that do not improve performance on the validation set, helping to reduce overfitting.\n",
        "\n",
        "**In essence, for a Decision Tree, the training data is for *building* the model, and the validation data is for *testing* and *evaluating* its generalization ability after it's built.**\n",
        "\n",
        "**Random Forests:**\n",
        "\n",
        "*   **Training Data:**\n",
        "    *   A Random Forest, being an ensemble method, trains **multiple Decision Trees**.\n",
        "    *   Each individual Decision Tree in the Random Forest is trained on a **different subset of the training data**. This subset is typically created using **bootstrap sampling** (sampling with replacement from the training data). In Pasting, it's sampling without replacement.\n",
        "    *   Because each tree is trained on a different subset of the training data, they become diverse and learn slightly different aspects of the data.\n",
        "    *   The feature randomness (considering only a subset of features at each split) also contributes to the diversity of the individual trees during training.\n",
        "\n",
        "*   **Validation Data:**\n",
        "    *   Similar to Decision Trees, validation data is **not directly used during the training of individual trees** within a Random Forest.\n",
        "    *   After all the trees in the Random Forest are trained, the **validation data is used to evaluate the performance of the *entire ensemble***.\n",
        "    *   To make a prediction for a validation data point, each tree in the Random Forest independently makes a prediction.\n",
        "    *   These individual predictions are then **aggregated** to get the final prediction of the Random Forest. For regression, predictions are typically averaged. For classification, they might be voted on (majority vote) or averaged (for predicted probabilities).\n",
        "    *   The validation data is used to calculate performance metrics (like MAE, accuracy) for these aggregated predictions, thus evaluating the generalization ability of the Random Forest as a whole.\n",
        "    *   **Hyperparameter Tuning:** Validation data plays a critical role in **hyperparameter tuning for Random Forests**. When you adjust hyperparameters like `n_estimators` or `max_depth`, you train multiple Random Forest models with different hyperparameter settings. You then use the validation data to compare the performance of these different models and choose the hyperparameter settings that yield the best performance on the validation set (indicating better generalization).\n",
        "\n",
        "**Key Differences in Handling Data:**\n",
        "\n",
        "| Feature           | Decision Tree                                  | Random Forest                                                                    |\n",
        "|--------------------|------------------------------------------------|---------------------------------------------------------------------------------|\n",
        "| **Training Data Usage** | Trained on the *entire* training dataset.    | Each tree trained on a *different subset* (bootstrap or pasting) of training data. |\n",
        "| **Validation Data Usage** | Used *after* training for evaluation and overfitting detection. | Used *after* ensemble training for evaluation, hyperparameter tuning, and generalization assessment. |\n",
        "| **Data Diversity in Training** | Learns from a single, complete training set. | Learns from multiple, diverse subsets of the training data (for each tree).    |\n",
        "| **Model Evaluation**| Evaluation of a *single* tree's performance.  | Evaluation of the *aggregated predictions* of the entire forest.                 |\n",
        "\n",
        "**In summary,** both Decision Trees and Random Forests use training data to learn and validation data to evaluate generalization. However, Random Forests leverage the training data more extensively by creating multiple models on different subsets, and the validation data is used to assess the performance of the *ensemble* prediction, especially during hyperparameter tuning to optimize generalization. The use of validation data remains crucial for both types to ensure models are not just memorizing training data but learning to make accurate predictions on new, unseen data."
      ],
      "metadata": {
        "id": "KRRX66nPMySi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn --upgrade"
      ],
      "metadata": {
        "id": "endtkAk3lrWn",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Code Cell 1: Importing necessary libraries\n",
        "\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, RandomForestClassifier, BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.datasets import load_digits, load_iris # For classification examples\n",
        "from sklearn.metrics import ConfusionMatrixDisplay # Import ConfusionMatrixDisplay instead of plot_confusion_matrix\n",
        "\n",
        "\n",
        "kagglehub.login()\n",
        "dansbecker_home_data_for_ml_course_path = kagglehub.dataset_download('dansbecker/home-data-for-ml-course')\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "id": "qTPYHCqrhD5X",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Code Cell 2: Loading Datasets - Iowa Housing (Regression), Digits (Classification), and Iris (Comparison)\n",
        "\n",
        "# Load Iowa Housing Dataset for Regression\n",
        "iowa_file_path = dansbecker_home_data_for_ml_course_path + '/train.csv'\n",
        "iowa_data = pd.read_csv(iowa_file_path)\n",
        "print(\"Iowa dataset (Regression) loaded successfully!\")\n",
        "\n",
        "# Load Digits Dataset for Classification\n",
        "digits = load_digits()\n",
        "digits_X, digits_y = digits.data, digits.target\n",
        "print(\"\\nDigits dataset (Classification) loaded successfully!\")\n",
        "\n",
        "# Load Iris Dataset for Comparison (Classification)\n",
        "iris = load_iris()\n",
        "iris_X, iris_y = iris.data, iris.target\n",
        "print(\"\\nIris dataset (Comparison) loaded successfully!\")"
      ],
      "metadata": {
        "id": "WQmCEX-hhGQ6",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explanation of Code Cell 2: Loading Datasets**\n",
        "\n",
        "In this code cell, we load **all three datasets** that we will use throughout this module at once:\n",
        "\n",
        "*   **Iowa Housing Dataset (for Regression):**\n",
        "    *   *(Explanation is the same as before)*\n",
        "\n",
        "*   **Digits Dataset (for Classification):**\n",
        "    *   *(Explanation is the same as before)*\n",
        "\n",
        "*   **Iris Dataset (for Dataset Comparison):**\n",
        "    *   `iris = load_iris()`: Loads the **Iris dataset** using `load_iris()` from `sklearn.datasets`. We load it now so it's ready for the dataset comparison in Step 10.\n",
        "    *   `iris_X, iris_y = iris.data, iris.target`: Separates Iris dataset into features (`iris_X`) and target labels (`iris_y`).\n",
        "    *   `print(\"\\nIris dataset (Comparison) loaded successfully!\")`: Confirmation message.\n",
        "\n",
        "By loading all datasets upfront, we ensure that all necessary data is available throughout the module, and we are ready to proceed with data preparation and model building."
      ],
      "metadata": {
        "id": "V1P1GCuFhJce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------\n",
        "# Step 1: Prepare Data for Regression (Iowa Dataset)\n",
        "#------------------------------------\n",
        "print(\"\\n\\n----- Step 1: Prepare Data for Regression (Iowa Dataset) -----\")\n",
        "\n",
        "iowa_y = iowa_data['SalePrice']\n",
        "print(\"Regression Target variable 'iowa_y' created successfully!\")\n",
        "\n",
        "iowa_numeric_features = iowa_data.select_dtypes(include=np.number)\n",
        "iowa_X = iowa_numeric_features.drop('SalePrice', axis=1)\n",
        "print(\"\\nRegression Predictive features 'iowa_X' created successfully!\")\n",
        "\n",
        "# Split data for Regression\n",
        "iowa_X_train, iowa_X_val, y_train, y_val = train_test_split(iowa_X, iowa_y, test_size=0.2, random_state=0)\n",
        "print(\"\\nRegression Data split into training and validation sets successfully!\")"
      ],
      "metadata": {
        "id": "eaGl72OrhMWx",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------\n",
        "# Step 2: Prepare Data for Classification (Digits Dataset)\n",
        "#------------------------------------\n",
        "print(\"\\n\\n----- Step 2: Prepare Data for Classification (Digits Dataset) -----\")\n",
        "\n",
        "digits_X = digits_X\n",
        "digits_y = digits_y\n",
        "print(\"Classification Features 'digits_X' and Target 'digits_y' created successfully!\")\n",
        "# Digits Dataset represents 8x8 Images: Each sample is a list of 64 numbers, representing the pixel values of an 8x8 image. To actually visualize the image, you would need to reshape this list into an 8x8 matrix. The numbers within the list correspond to the intensity of each pixel in grayscale. They range from 0 (black) to 16 (white).\n",
        "\n",
        "# Split data for Classification\n",
        "digits_X_train, digits_X_val, digits_y_train, digits_y_val = train_test_split(digits_X, digits_y, test_size=0.2, random_state=0)\n",
        "print(\"\\nClassification Data split into training and validation sets successfully!\")\n",
        "\n",
        "# Print shapes of the data\n",
        "print(\"Shape of digits_X_train:\", digits_X_train.shape)\n",
        "print(\"Shape of digits_y_train:\", digits_y_train.shape)\n",
        "print(\"Shape of digits_X_val:\", digits_X_val.shape)\n",
        "print(\"Shape of digits_y_val:\", digits_y_val.shape)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Print some examples from the training data\n",
        "print(\"\\nFirst 5 samples of digits_X_train:\")\n",
        "print(digits_X_train[:5])\n",
        "print(\"\\nFirst 5 labels of digits_y_train:\")\n",
        "print(digits_y_train[:5])\n",
        "print(\"\\n\")\n",
        "\n",
        "# Print some examples from the validation data\n",
        "print(\"\\nFirst 5 samples of digits_X_val:\")\n",
        "print(digits_X_val[:5])\n",
        "print(\"\\nFirst 5 labels of digits_y_val:\")\n",
        "print(digits_y_val[:5])\n",
        "print(\"\\n\")\n",
        "\n",
        "# Print unique values of target variable in training and validation sets\n",
        "print(\"\\nUnique values in digits_y_train:\", np.unique(digits_y_train))\n",
        "print(\"Unique values in digits_y_val:\", np.unique(digits_y_val))\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "Jmn8gcv1hPC-",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explanation of Code Cell for Step 2: Prepare Data for Classification (Digits Dataset)**\n",
        "\n",
        "This code cell focuses on preparing the **Digits dataset** specifically for classification tasks. It takes the already loaded Digits dataset (from Code Cell 2) and splits it into training and validation sets, ready for model training and evaluation. Here's a breakdown:\n",
        "\n",
        "*   `print(\"\\n\\n----- Step 2: Prepare Data for Classification (Digits Dataset) -----\")`: This line simply prints a heading to clearly indicate the start of Step 2 and that it's dealing with the Digits dataset for classification.\n",
        "\n",
        "*   `digits_X = digits_X`\n",
        "    `digits_y = digits_y`:\n",
        "    These lines might seem redundant, but they explicitly assign the features (`digits_X`) and target labels (`digits_y`) from the loaded `digits` object to variables with the same names. In practice, this step ensures that we are using the correct feature and target data for the subsequent operations.\n",
        "\n",
        "*   `print(\"Classification Features 'digits_X' and Target 'digits_y' created successfully!\")`: This line prints a confirmation message to indicate that the feature and target variables for classification have been successfully prepared.\n",
        "\n",
        "*   `digits_X_train, digits_X_val, digits_y_train, digits_y_val = train_test_split(digits_X, digits_y, test_size=0.2, random_state=0)`:\n",
        "    This is the core of the data preparation step. It uses the `train_test_split` function from `sklearn.model_selection` to divide the Digits dataset into training and validation sets.\n",
        "    *   `digits_X` and `digits_y`: These are the feature matrix and target variable for the Digits dataset, which are being split.\n",
        "    *   `test_size=0.2`: This argument specifies that 20% of the data should be reserved for the validation set, and the remaining 80% will be used for training.\n",
        "    *   `random_state=0`: This sets a seed for the random number generator used by the `train_test_split` function. Setting a `random_state` ensures that the data split is reproducible. If you run the code multiple times, you will get the same training and validation sets.\n",
        "    *   The function returns four variables:\n",
        "        *   `digits_X_train`: Features for the training set.\n",
        "        *   `digits_X_val`: Features for the validation set.\n",
        "        *   `digits_y_train`: Target labels for the training set.\n",
        "        *   `digits_y_val`: Target labels for the validation set.\n",
        "\n",
        "*   `print(\"\\nClassification Data split into training and validation sets successfully!\")`: This line prints a confirmation message indicating that the Digits classification data has been successfully split into training and validation sets.\n",
        "\n",
        "In summary, this code cell takes the Digits dataset and prepares it for classification modeling by splitting it into distinct training and validation portions. This split is crucial to train models on one part of the data and then evaluate their performance on unseen data (the validation set), providing a realistic estimate of how well the models will generalize to new, real-world examples."
      ],
      "metadata": {
        "id": "79LiLqjgkQFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------\n",
        "# Step 0: Decision Tree - Baseline Models (Regressor and Classifier)\n",
        "#------------------------------------\n",
        "print(\"\\n\\n----- Step 0: Decision Tree - Baseline Models (Regressor and Classifier) -----\")\n",
        "# Explanation: Create and evaluate single Decision Tree models as baselines for regression and classification.\n",
        "\n",
        "# 0.1 Create and Train DecisionTreeRegressor Baseline\n",
        "baseline_tree_regressor = DecisionTreeRegressor(random_state=0)\n",
        "baseline_tree_regressor.fit(iowa_X_train, y_train)\n",
        "print(\"DecisionTreeRegressor baseline model trained successfully for Regression!\")\n",
        "\n",
        "# 0.2 Make predictions and evaluate DecisionTreeRegressor (Regression)\n",
        "baseline_regressor_predictions = baseline_tree_regressor.predict(iowa_X_val)\n",
        "mae_baseline_regressor = mean_absolute_error(y_val, baseline_regressor_predictions)\n",
        "mse_baseline_regressor = mean_squared_error(y_val, baseline_regressor_predictions)\n",
        "print(f\"MAE of DecisionTreeRegressor baseline (Regression): {mae_baseline_regressor}\")\n",
        "print(f\"MSE of DecisionTreeRegressor baseline (Regression): {mse_baseline_regressor}\")\n",
        "\n",
        "# 0.3 Create and Train DecisionTreeClassifier Baseline\n",
        "baseline_tree_classifier = DecisionTreeClassifier(random_state=0)\n",
        "baseline_tree_classifier.fit(digits_X_train, digits_y_train)\n",
        "print(\"\\nDecisionTreeClassifier baseline model trained successfully for Classification!\")\n",
        "\n",
        "# 0.4 Make predictions and evaluate DecisionTreeClassifier (Classification)\n",
        "baseline_classifier_predictions = baseline_tree_classifier.predict(digits_X_val)\n",
        "accuracy_baseline_classifier = accuracy_score(digits_y_val, baseline_classifier_predictions)\n",
        "print(f\"Accuracy of DecisionTreeClassifier baseline (Classification): {accuracy_baseline_classifier}\")\n",
        "print(\"\\nClassification Report for DecisionTreeClassifier baseline:\")\n",
        "print(classification_report(digits_y_val, baseline_classifier_predictions))\n",
        "print(\"\\nConfusion Matrix for DecisionTreeClassifier baseline:\")\n",
        "print(confusion_matrix(digits_y_val, baseline_classifier_predictions))\n",
        "\n",
        "# Explanation:\n",
        "# We are creating simple Decision Tree Regressor and Classifier models as baselines\n",
        "# to compare against ensemble methods later. We train them, make predictions, and evaluate\n",
        "# their performance using appropriate metrics for regression (MAE, MSE) and\n",
        "# classification (Accuracy, Classification Report, Confusion Matrix).\n",
        "\n",
        "# 0.5 Plotting Predictions of Decision Tree Regressor (Regression)\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(y_val, baseline_regressor_predictions, alpha=0.5)\n",
        "plt.xlabel(\"Actual Prices\")\n",
        "plt.ylabel(\"Predicted Prices\")\n",
        "plt.title(\"Decision Tree Regressor: Actual vs Predicted (Baseline Regression Model)\")\n",
        "plt.plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], color='red')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 0.6 Plotting Confusion Matrix of Decision Tree Classifier (Classification)\n",
        "cm = confusion_matrix(digits_y_val, baseline_classifier_predictions)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(digits_y))\n",
        "disp.plot(cmap=plt.cm.Blues) # Use cmap for color scheme\n",
        "plt.title('Confusion Matrix - Decision Tree Classifier (Baseline Classification Model - Digits)') # Updated title\n",
        "plt.xticks(rotation=45) # Rotate x-axis labels for better visibility\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oKlWhPVBhT1s",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretation of Classification Report for Digit Classification\n",
        "\n",
        "The output you provided is a classification report, which shows the performance of your machine learning model on classifying handwritten digits (0-9). Here's a breakdown:\n",
        "\n",
        "**Structure:**\n",
        "\n",
        "1. **Per-Class Metrics:**\n",
        "   - The first 10 rows (for digits 0 through 9) provide individual metrics for each class:\n",
        "     - **precision:** Out of all the times the model predicted a specific digit, what proportion was actually correct?\n",
        "     \n",
        "      - **Precision = True Positives / (True Positives + False Positives)**\n",
        "\n",
        "     - **recall:** Out of all the actual instances of a specific digit, what proportion did the model correctly identify?\n",
        "\n",
        "      -  **Recall = True Positives / (True Positives + False Negatives)**\n",
        "\n",
        "     - **f1-score:** A balanced measure considering both precision and recall.\n",
        "     - **support:** The number of actual instances of that digit in your dataset.\n",
        "\n",
        "2. **Overall Metrics:**\n",
        "   - **accuracy:** The overall proportion of correctly classified digits. In this case, it's 85%, meaning the model got 85% of the digits right.\n",
        "   - **macro avg:** Averages the precision, recall, and F1-score across all classes *without* considering class imbalances (equal weight to each class).\n",
        "   - **weighted avg:** Averages the precision, recall, and F1-score across all classes, taking into account the number of instances in each class (weighted by support).\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "- **Accuracy (0.85):** Your model has an overall accuracy of 85%, which is a good starting point.\n",
        "- **Per-Class Performance:**\n",
        "    - The model performs well on most digits (precision, recall, and F1-score above 0.8 for many).\n",
        "    - Digit '8' seems to have lower performance, especially in terms of recall (0.62). This means the model might be missing a significant number of actual '8's.\n",
        "- **Macro vs. Weighted Average:**\n",
        "    - Since the macro and weighted averages are very close (both 0.85), it suggests that your classes (digits 0-9) are relatively balanced in the dataset.\n",
        "\n",
        "**Insights and Next Steps:**\n",
        "\n",
        "- **Focus on '8':** Investigate why the model is struggling with digit '8'. Consider collecting more data for '8's or adjusting model parameters to improve recognition.\n",
        "- **Overall Improvement:** Experiment with different model settings or ensemble methods (Bagging, Random Forest, etc.) to try and boost the overall accuracy and per-class performance.\n",
        "- **Data Augmentation:** If you have limited data for specific digits, consider techniques like data augmentation (rotating, shifting existing images) to synthetically increase the training set.\n",
        "- **Feature Engineering:** Analyze the image data to see if you can extract more informative features that might help the model differentiate between digits more effectively."
      ],
      "metadata": {
        "id": "4FnMCHDwyXYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explanation of Code Cell for Step 0: Decision Tree - Baseline Models (Regressor and Classifier)**\n",
        "\n",
        "This code cell establishes **baseline performance** using single **Decision Tree models** for both regression and classification tasks. These baselines will serve as a point of comparison to evaluate the improvements offered by ensemble methods in subsequent steps.\n",
        "\n",
        "**Regression Baseline (DecisionTreeRegressor):**\n",
        "\n",
        "*   `print(\"\\n\\n----- Step 0: Decision Tree - Baseline Models (Regressor and Classifier) -----\")`: Prints a heading for Step 0, indicating the creation of baseline models.\n",
        "\n",
        "*   `baseline_tree_regressor = DecisionTreeRegressor(random_state=0)`:\n",
        "    This line creates a `DecisionTreeRegressor` object from `sklearn.tree`.\n",
        "    *   `DecisionTreeRegressor()`: Initializes a Decision Tree Regressor model.\n",
        "    *   `random_state=0`: Sets a seed for the random number generator within the Decision Tree algorithm to ensure reproducibility.\n",
        "\n",
        "*   `baseline_tree_regressor.fit(iowa_X_train, y_train)`:\n",
        "    This line trains the `baseline_tree_regressor` model using the training data prepared for regression (Iowa dataset).\n",
        "    *   `.fit(iowa_X_train, y_train)`:  The `.fit()` method is used to train the model. It takes the training features (`iowa_X_train`) and the corresponding training target variable (`y_train`) as input.\n",
        "\n",
        "*   `print(\"DecisionTreeRegressor baseline model trained successfully for Regression!\")`: Confirmation message after training the regression baseline model.\n",
        "\n",
        "*   `baseline_regressor_predictions = baseline_tree_regressor.predict(iowa_X_val)`:\n",
        "    This line uses the trained `baseline_tree_regressor` to make predictions on the validation set for the Iowa housing data.\n",
        "    *   `.predict(iowa_X_val)`: The `.predict()` method takes the validation features (`iowa_X_val`) as input and generates predictions based on the trained model.\n",
        "\n",
        "*   `mae_baseline_regressor = mean_absolute_error(y_val, baseline_regressor_predictions)`:\n",
        "    `mse_baseline_regressor = mean_squared_error(y_val, baseline_regressor_predictions)`:\n",
        "    These lines calculate the performance metrics for the regression baseline model.\n",
        "    *   `mean_absolute_error(y_val, baseline_regressor_predictions)`: Calculates the Mean Absolute Error (MAE) between the true validation target values (`y_val`) and the predictions made by the baseline regressor (`baseline_regressor_predictions`). MAE measures the average absolute difference between predictions and actual values.\n",
        "    *   `mean_squared_error(y_val, baseline_regressor_predictions)`: Calculates the Mean Squared Error (MSE) between the true validation target values (`y_val`) and the predictions. MSE measures the average squared difference between predictions and actual values.\n",
        "\n",
        "*   `print(f\"MAE of DecisionTreeRegressor baseline (Regression): {mae_baseline_regressor}\")`\n",
        "    `print(f\"MSE of DecisionTreeRegressor baseline (Regression): {mse_baseline_regressor}\")`:\n",
        "    These lines print the calculated MAE and MSE values for the Decision Tree Regressor baseline.\n",
        "\n",
        "**Classification Baseline (DecisionTreeClassifier):**\n",
        "\n",
        "*   `baseline_tree_classifier = DecisionTreeClassifier(random_state=0)`:\n",
        "    Creates a `DecisionTreeClassifier` object from `sklearn.tree` for classification baseline.  Similar to the regressor, `random_state=0` ensures reproducibility.\n",
        "\n",
        "*   `baseline_tree_classifier.fit(digits_X_train, digits_y_train)`:\n",
        "    Trains the `baseline_tree_classifier` using the training data prepared for classification (Digits dataset).\n",
        "\n",
        "*   `print(\"\\nDecisionTreeClassifier baseline model trained successfully for Classification!\")`: Confirmation message after training the classification baseline model.\n",
        "\n",
        "*   `baseline_classifier_predictions = baseline_tree_classifier.predict(digits_X_val)`:\n",
        "    Makes predictions using the trained `baseline_tree_classifier` on the validation set of the Digits dataset.\n",
        "\n",
        "*   `accuracy_baseline_classifier = accuracy_score(digits_y_val, baseline_classifier_predictions)`:\n",
        "    Calculates the accuracy score for the classification baseline model.\n",
        "    *   `accuracy_score(digits_y_val, baseline_classifier_predictions)`: Calculates the accuracy, which is the proportion of correctly classified instances (predictions matching the true labels `digits_y_val`).\n",
        "\n",
        "*   `print(f\"Accuracy of DecisionTreeClassifier baseline (Classification): {accuracy_baseline_classifier}\")`:\n",
        "    Prints the accuracy score for the Decision Tree Classifier baseline.\n",
        "\n",
        "*   `print(\"\\nClassification Report for DecisionTreeClassifier baseline:\")`\n",
        "    `print(classification_report(digits_y_val, baseline_classifier_predictions))`:\n",
        "    Prints a detailed classification report.\n",
        "    *   `classification_report(digits_y_val, baseline_classifier_predictions)`: Generates a classification report that includes precision, recall, F1-score, and support for each class in the Digits dataset. This provides a more comprehensive view of the classifier's performance beyond just accuracy, especially in multi-class classification problems like Digits.\n",
        "\n",
        "*   `print(\"\\nConfusion Matrix for DecisionTreeClassifier baseline:\")`\n",
        "    `print(confusion_matrix(digits_y_val, baseline_classifier_predictions))`:\n",
        "    Prints the confusion matrix.\n",
        "    *   `confusion_matrix(digits_y_val, baseline_classifier_predictions)`: Generates a confusion matrix, which is a table showing the counts of true positive, true negative, false positive, and false negative predictions for each class. It helps to visualize the performance of a classifier in terms of which classes are being confused with each other.\n",
        "\n",
        "**Plotting (Regression and Classification):**\n",
        "\n",
        "*   **Regression Plot (Actual vs Predicted Prices):**\n",
        "    *   Uses `matplotlib.pyplot` to create a scatter plot of actual vs. predicted prices for the `DecisionTreeRegressor`. This visual helps to assess how well the model's predictions align with the actual values. The red diagonal line represents perfect predictions.\n",
        "\n",
        "*   **Classification Plot (Confusion Matrix):**\n",
        "    *   Uses `matplotlib.pyplot` to display the confusion matrix for the `DecisionTreeClassifier` as a heatmap. The confusion matrix is visualized using `plt.imshow()`, and colorbar and labels are added for clarity. The tick marks and labels are adjusted to represent the 10 digits classes correctly. This plot provides a visual representation of the classifier's performance in classifying each digit and helps identify potential areas of confusion between different digits.\n",
        "\n",
        "In essence, Step 0 establishes the performance of single Decision Tree models as a starting point. By evaluating both regression and classification Decision Trees and visualizing their performance, we have a clear baseline to compare against the ensemble methods that will be introduced in the following steps. This allows us to quantify the benefits of using ensemble techniques."
      ],
      "metadata": {
        "id": "1dX0gNnFkV9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------\n",
        "# Step 1: Bagging - Regression and Classification\n",
        "#------------------------------------\n",
        "print(\"\\n\\n----- Step 1: Bagging - Regression and Classification -----\")\n",
        "# Explanation: Create and evaluate Bagging ensembles for both regression and classification, comparing to Decision Tree baselines.\n",
        "\n",
        "# 1.1 Create and Train BaggingRegressor\n",
        "# Use 'estimator' instead of 'base_estimator'\n",
        "bagging_regressor = BaggingRegressor(estimator=DecisionTreeRegressor(random_state=0), n_estimators=10, random_state=0)\n",
        "bagging_regressor.fit(iowa_X_train, y_train)\n",
        "print(\"\\nBaggingRegressor model trained successfully!\")\n",
        "\n",
        "# 1.2 Make predictions and evaluate BaggingRegressor (Regression)\n",
        "bagging_regressor_predictions = bagging_regressor.predict(iowa_X_val)\n",
        "mae_bagging_regressor = mean_absolute_error(y_val, bagging_regressor_predictions)\n",
        "mse_bagging_regressor = mean_squared_error(y_val, bagging_regressor_predictions)\n",
        "print(f\"MAE of BaggingRegressor (Regression): {mae_bagging_regressor}\")\n",
        "print(f\"MSE of BaggingRegressor (Regression): {mse_bagging_regressor}\")\n",
        "print(f\"Improvement in MAE over DecisionTreeRegressor: {mae_baseline_regressor - mae_bagging_regressor:.2f}\")\n",
        "print(f\"Improvement in MSE over DecisionTreeRegressor: {mse_baseline_regressor - mse_bagging_regressor:.2f}\")\n",
        "\n",
        "# 1.3 Create and Train BaggingClassifier\n",
        "# Use 'estimator' instead of 'base_estimator'\n",
        "bagging_classifier = BaggingClassifier(estimator=DecisionTreeClassifier(random_state=0), n_estimators=10, random_state=0)\n",
        "bagging_classifier.fit(digits_X_train, digits_y_train)\n",
        "print(\"\\nBaggingClassifier model trained successfully!\")\n",
        "\n",
        "# 1.4 Make predictions and evaluate BaggingClassifier (Classification)\n",
        "bagging_classifier_predictions = bagging_classifier.predict(digits_X_val)\n",
        "accuracy_bagging_classifier = accuracy_score(digits_y_val, bagging_classifier_predictions)\n",
        "print(f\"Accuracy of BaggingClassifier (Classification): {accuracy_bagging_classifier}\")\n",
        "print(f\"Improvement in Accuracy over DecisionTreeClassifier: {accuracy_bagging_classifier - accuracy_baseline_classifier:.2f}\")\n",
        "print(\"\\nClassification Report for BaggingClassifier:\")\n",
        "print(classification_report(digits_y_val, bagging_classifier_predictions))\n",
        "print(\"\\nConfusion Matrix for BaggingClassifier:\")\n",
        "print(confusion_matrix(digits_y_val, bagging_classifier_predictions))\n",
        "\n",
        "# Explanation:\n",
        "# We are creating Bagging ensembles for both regression and classification using\n",
        "# Decision Trees as base estimators. We train them, make predictions, and\n",
        "# evaluate their performance, comparing against the Decision Tree baselines.\n",
        "\n",
        "# 1.5 Plotting Predictions of BaggingRegressor (Regression)\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(y_val, bagging_regressor_predictions, alpha=0.5)\n",
        "plt.xlabel(\"Actual Prices\")\n",
        "plt.ylabel(\"Predicted Prices\")\n",
        "plt.title(\"BaggingRegressor: Actual vs Predicted (Ensemble Regression Model)\")\n",
        "plt.plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], color='red')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 1.6 Plotting Confusion Matrix of BaggingClassifier (Classification)\n",
        "# Instead of using plot_confusion_matrix, use ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(digits_y_val, bagging_classifier_predictions)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(digits_y))\n",
        "disp.plot(cmap=plt.cm.Blues) # Use cmap for color scheme\n",
        "plt.title('Confusion Matrix - BaggingClassifier (Ensemble Classification Model - Digits)')\n",
        "plt.xticks(rotation=45) # Rotate x-axis labels for better visibility\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2u9ERLIEqim-",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explanation of Code Cell for Step 1: Bagging - Regression and Classification**\n",
        "\n",
        "This code cell implements and evaluates **Bagging ensembles** for both regression and classification tasks. Bagging (Bootstrap Aggregating) is an ensemble technique that involves training multiple instances of the same base learner (in this case, Decision Trees) on different bootstrapped subsets of the training data. The predictions of these base learners are then aggregated (averaged for regression, voted for classification) to make the final prediction.\n",
        "\n",
        "**Bagging Regressor (BaggingRegressor):**\n",
        "\n",
        "*   `print(\"\\n\\n----- Step 1: Bagging - Regression and Classification -----\")`: Prints a heading for Step 1, indicating Bagging models.\n",
        "\n",
        "*   `bagging_regressor = BaggingRegressor(base_estimator=DecisionTreeRegressor(random_state=0), n_estimators=10, random_state=0)`:\n",
        "    This line creates a `BaggingRegressor` object from `sklearn.ensemble`.\n",
        "    *   `BaggingRegressor(...)`: Initializes a Bagging Regressor ensemble.\n",
        "    *   `base_estimator=DecisionTreeRegressor(random_state=0)`: Specifies that the base learner for Bagging is a `DecisionTreeRegressor`. We are using Decision Trees as the building blocks of our Bagging ensemble. `random_state=0` ensures the Decision Tree base estimator is also reproducible.\n",
        "    *   `n_estimators=10`: Sets the number of base estimators (Decision Trees) in the Bagging ensemble to 10. This means the Bagging ensemble will consist of 10 Decision Trees.\n",
        "    *   `random_state=0`: Sets a seed for the random number generator used by the Bagging process itself (e.g., for bootstrapping). This ensures the Bagging ensemble creation is reproducible.\n",
        "\n",
        "*   `bagging_regressor.fit(iowa_X_train, y_train)`:\n",
        "    Trains the `bagging_regressor` ensemble using the Iowa housing training data.  This step will train 10 Decision Tree regressors, each on a different bootstrapped sample of the training data.\n",
        "\n",
        "*   `print(\"\\nBaggingRegressor model trained successfully!\")`: Confirmation message after training the Bagging Regressor model.\n",
        "\n",
        "*   `bagging_regressor_predictions = bagging_regressor.predict(iowa_X_val)`:\n",
        "    Uses the trained `bagging_regressor` ensemble to make predictions on the Iowa housing validation set. The predictions from all 10 Decision Trees in the ensemble are averaged to get the final prediction for each instance.\n",
        "\n",
        "*   `mae_bagging_regressor = mean_absolute_error(y_val, bagging_regressor_predictions)`:\n",
        "    `mse_bagging_regressor = mean_squared_error(y_val, bagging_regressor_predictions)`:\n",
        "    Calculates the MAE and MSE for the Bagging Regressor, similar to the baseline evaluation in Step 0.\n",
        "\n",
        "*   `print(f\"MAE of BaggingRegressor (Regression): {mae_bagging_regressor}\")`\n",
        "    `print(f\"MSE of BaggingRegressor (Regression): {mse_bagging_regressor}\")`:\n",
        "    Prints the MAE and MSE of the Bagging Regressor.\n",
        "\n",
        "*   `print(f\"Improvement in MAE over DecisionTreeRegressor: {mae_baseline_regressor - mae_bagging_regressor:.2f}\")`\n",
        "    `print(f\"Improvement in MSE over DecisionTreeRegressor: {mse_baseline_regressor - mse_bagging_regressor:.2f}\")`:\n",
        "    Calculates and prints the improvement in MAE and MSE achieved by Bagging Regressor compared to the Decision Tree Regressor baseline from Step 0. This helps to quantify the benefit of using Bagging.\n",
        "\n",
        "**Bagging Classifier (BaggingClassifier):**\n",
        "\n",
        "*   `bagging_classifier = BaggingClassifier(base_estimator=DecisionTreeClassifier(random_state=0), n_estimators=10, random_state=0)`:\n",
        "    Creates a `BaggingClassifier` object from `sklearn.ensemble`. It is configured similarly to `BaggingRegressor`, but for classification. It uses `DecisionTreeClassifier` as the base estimator and also uses 10 estimators.\n",
        "\n",
        "*   `bagging_classifier.fit(digits_X_train, digits_y_train)`:\n",
        "    Trains the `bagging_classifier` ensemble using the Digits training data. This will train 10 Decision Tree classifiers, each on a bootstrapped sample.\n",
        "\n",
        "*   `print(\"\\nBaggingClassifier model trained successfully!\")`: Confirmation message.\n",
        "\n",
        "*   `bagging_classifier_predictions = bagging_classifier.predict(digits_X_val)`:\n",
        "    Makes predictions using the trained `bagging_classifier` ensemble on the Digits validation set. For classification, the predictions are typically made by majority voting among the 10 Decision Tree classifiers.\n",
        "\n",
        "*   `accuracy_bagging_classifier = accuracy_score(digits_y_val, bagging_classifier_predictions)`:\n",
        "    Calculates the accuracy of the Bagging Classifier.\n",
        "\n",
        "*   `print(f\"Accuracy of BaggingClassifier (Classification): {accuracy_bagging_classifier}\")`\n",
        "    `print(f\"Improvement in Accuracy over DecisionTreeClassifier: {accuracy_bagging_classifier - accuracy_baseline_classifier:.2f}\")`:\n",
        "    Prints the accuracy and the improvement in accuracy over the Decision Tree Classifier baseline.\n",
        "\n",
        "*   `print(\"\\nClassification Report for BaggingClassifier:\")`\n",
        "    `print(classification_report(digits_y_val, bagging_classifier_predictions))`:\n",
        "    `print(\"\\nConfusion Matrix for BaggingClassifier:\")`\n",
        "    `print(confusion_matrix(digits_y_val, bagging_classifier_predictions))`:\n",
        "    Prints the classification report and confusion matrix for the Bagging Classifier, providing detailed performance evaluation.\n",
        "\n",
        "**Plotting (Regression and Classification):**\n",
        "\n",
        "*   **Regression Plot (Actual vs Predicted Prices for BaggingRegressor):**\n",
        "    *   Creates a scatter plot of actual vs. predicted prices for the `BaggingRegressor`, similar to the baseline plot in Step 0.\n",
        "\n",
        "*   **Classification Plot (Confusion Matrix for BaggingClassifier):**\n",
        "    *   Displays the confusion matrix for the `BaggingClassifier` as a heatmap, again similar to the baseline plot but now for the Bagging model. The plot is adapted for the 10 classes of the Digits dataset.\n",
        "\n",
        "In summary, Step 1 implements Bagging for both regression and classification using Decision Trees as base learners. It trains and evaluates these Bagging ensembles, calculates performance metrics, and visualizes the results. Crucially, it compares the performance of Bagging to the Decision Tree baselines from Step 0, allowing students to observe the potential benefits of ensemble methods in improving model accuracy and robustness."
      ],
      "metadata": {
        "id": "MtKAYtmNkbfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------\n",
        "# Step 2: Pasting - Regression and Classification\n",
        "#------------------------------------\n",
        "print(\"\\n\\n----- Step 2: Pasting - Regression and Classification -----\")\n",
        "# Explanation: Create and evaluate Pasting ensembles for both regression and classification, comparing to Decision Tree and Bagging models.\n",
        "\n",
        "# 2.1 Create and Train PastingRegressor\n",
        "pasting_regressor = BaggingRegressor(estimator=DecisionTreeRegressor(random_state=0), # Changed 'base_estimator' to 'estimator'\n",
        "                                     n_estimators=10,\n",
        "                                     random_state=0,\n",
        "                                     bootstrap=False)\n",
        "\n",
        "pasting_regressor.fit(iowa_X_train, y_train)\n",
        "print(\"\\nPastingRegressor model trained successfully!\")\n",
        "\n",
        "# 2.2 Make predictions and evaluate PastingRegressor (Regression)\n",
        "pasting_regressor_predictions = pasting_regressor.predict(iowa_X_val)\n",
        "mae_pasting_regressor = mean_absolute_error(y_val, pasting_regressor_predictions)\n",
        "mse_pasting_regressor = mean_squared_error(y_val, pasting_regressor_predictions)\n",
        "print(f\"MAE of PastingRegressor (Regression): {mae_pasting_regressor}\")\n",
        "print(f\"MSE of PastingRegressor (Regression): {mse_pasting_regressor}\")\n",
        "print(f\"Improvement in MAE over DecisionTreeRegressor: {mae_baseline_regressor - mae_pasting_regressor:.2f}\")\n",
        "print(f\"Improvement in MSE over DecisionTreeRegressor: {mse_baseline_regressor - mse_pasting_regressor:.2f}\")\n",
        "print(f\"Comparison of MAE with BaggingRegressor: {mae_bagging_regressor - mae_pasting_regressor:.2f}\")\n",
        "print(f\"Comparison of MSE with BaggingRegressor: {mse_bagging_regressor - mse_pasting_regressor:.2f}\")\n",
        "\n",
        "\n",
        "# 2.3 Create and Train PastingClassifier\n",
        "pasting_classifier = BaggingClassifier(estimator=DecisionTreeClassifier(random_state=0),  # Changed 'base_estimator' to 'estimator'\n",
        "                                       n_estimators=10,\n",
        "                                       random_state=0,\n",
        "                                       bootstrap=False)\n",
        "\n",
        "pasting_classifier.fit(digits_X_train, digits_y_train)\n",
        "print(\"\\nPastingClassifier model trained successfully!\")\n",
        "\n",
        "# 2.4 Make predictions and evaluate PastingClassifier (Classification)\n",
        "pasting_classifier_predictions = pasting_classifier.predict(digits_X_val)\n",
        "accuracy_pasting_classifier = accuracy_score(digits_y_val, pasting_classifier_predictions)\n",
        "print(f\"Accuracy of PastingClassifier (Classification): {accuracy_pasting_classifier}\")\n",
        "print(f\"Improvement in Accuracy over DecisionTreeClassifier: {accuracy_pasting_classifier - accuracy_baseline_classifier:.2f}\")\n",
        "print(f\"Comparison of Accuracy with BaggingClassifier: {accuracy_bagging_classifier - accuracy_pasting_classifier:.2f}\")\n",
        "print(\"\\nClassification Report for PastingClassifier:\")\n",
        "print(classification_report(digits_y_val, pasting_classifier_predictions))\n",
        "print(\"\\nConfusion Matrix for PastingClassifier:\")\n",
        "print(confusion_matrix(digits_y_val, pasting_classifier_predictions))\n",
        "\n",
        "# Explanation:\n",
        "# We are creating Pasting ensembles for both regression and classification using\n",
        "# Decision Trees as base estimators. We train them, make predictions, and\n",
        "# evaluate their performance, comparing against Decision Tree and Bagging models.\n",
        "\n",
        "# 2.5 Plotting Predictions of PastingRegressor (Regression)\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(y_val, pasting_regressor_predictions, alpha=0.5)\n",
        "plt.xlabel(\"Actual Prices\")\n",
        "plt.ylabel(\"Predicted Prices\")\n",
        "plt.title(\"PastingRegressor: Actual vs Predicted (Ensemble Regression Model)\")\n",
        "plt.plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], color='red')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 2.6 Plotting Confusion Matrix of PastingClassifier (Classification)\n",
        "cm = confusion_matrix(digits_y_val, pasting_classifier_predictions)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(digits_y))\n",
        "disp.plot(cmap=plt.cm.Blues) # Use cmap for color scheme\n",
        "plt.title('Confusion Matrix - Decision Tree Classifier (Baseline Classification Model - Digits)') # Updated title\n",
        "plt.xticks(rotation=45) # Rotate x-axis labels for better visibility\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LphRiqechch0",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explanation of Code Cell for Step 2: Pasting - Regression and Classification**\n",
        "\n",
        "This code cell implements and evaluates **Pasting ensembles** for both regression and classification tasks. Pasting is very similar to Bagging, but the key difference is in the data sampling method. While Bagging uses **bootstrapping** (sampling with replacement), Pasting uses **sampling without replacement**. This means each base learner in a Pasting ensemble is trained on a slightly different subset of the original training data, but these subsets are disjoint (no data points are repeated within a single subset).\n",
        "\n",
        "**Pasting Regressor (PastingRegressor):**\n",
        "\n",
        "*   `print(\"\\n\\n----- Step 2: Pasting - Regression and Classification -----\")`: Prints a heading for Step 2, indicating Pasting models.\n",
        "\n",
        "*   `pasting_regressor = PastingRegressor(base_estimator=DecisionTreeRegressor(random_state=0), n_estimators=10, random_state=0)`:\n",
        "    Creates a `PastingRegressor` object from `sklearn.ensemble`.\n",
        "    *   `PastingRegressor(...)`: Initializes a Pasting Regressor ensemble.\n",
        "    *   `base_estimator=DecisionTreeRegressor(random_state=0)`:  Similar to Bagging, it uses `DecisionTreeRegressor` as the base learner.\n",
        "    *   `n_estimators=10`: Sets the number of base estimators to 10.\n",
        "    *   `random_state=0`: Sets a seed for reproducibility.\n",
        "\n",
        "*   `pasting_regressor.fit(iowa_X_train, y_train)`:\n",
        "    Trains the `pasting_regressor` ensemble using the Iowa housing training data.  This trains 10 Decision Tree regressors, each on a different subset of the training data sampled *without* replacement.\n",
        "\n",
        "*   `print(\"\\nPastingRegressor model trained successfully!\")`: Confirmation message.\n",
        "\n",
        "*   `pasting_regressor_predictions = pasting_regressor.predict(iowa_X_val)`:\n",
        "    Makes predictions using the trained `pasting_regressor` on the Iowa housing validation set. Predictions are aggregated (averaged) from the 10 base regressors.\n",
        "\n",
        "*   `mae_pasting_regressor = mean_absolute_error(y_val, pasting_regressor_predictions)`:\n",
        "    `mse_pasting_regressor = mean_squared_error(y_val, pasting_regressor_predictions)`:\n",
        "    Calculates MAE and MSE for the Pasting Regressor.\n",
        "\n",
        "*   `print(f\"MAE of PastingRegressor (Regression): {mae_pasting_regressor}\")`\n",
        "    `print(f\"MSE of PastingRegressor (Regression): {mse_pasting_regressor}\")`:\n",
        "    Prints the MAE and MSE.\n",
        "\n",
        "*   `print(f\"Improvement in MAE over DecisionTreeRegressor: {mae_baseline_regressor - mae_pasting_regressor:.2f}\")`\n",
        "    `print(f\"Improvement in MSE over DecisionTreeRegressor: {mse_baseline_regressor - mse_pasting_regressor:.2f}\")`:\n",
        "    Calculates and prints the improvement over the Decision Tree Regressor baseline.\n",
        "\n",
        "*   `print(f\"Comparison of MAE with BaggingRegressor: {mae_bagging_regressor - mae_pasting_regressor:.2f}\")`\n",
        "    `print(f\"Comparison of MSE with BaggingRegressor: {mse_bagging_regressor - mse_pasting_regressor:.2f}\")`:\n",
        "    Calculates and prints a comparison of MAE and MSE between Pasting and Bagging Regressors, allowing for a direct performance comparison between these two ensemble techniques.\n",
        "\n",
        "**Pasting Classifier (PastingClassifier):**\n",
        "\n",
        "*   `pasting_classifier = PastingClassifier(base_estimator=DecisionTreeClassifier(random_state=0), n_estimators=10, random_state=0)`:\n",
        "    Creates a `PastingClassifier` object, configured similarly to `PastingRegressor` but for classification using `DecisionTreeClassifier` as the base estimator.\n",
        "\n",
        "*   `pasting_classifier.fit(digits_X_train, digits_y_train)`:\n",
        "    Trains the `pasting_classifier` ensemble on the Digits training data.\n",
        "\n",
        "*   `print(\"\\nPastingClassifier model trained successfully!\")`: Confirmation message.\n",
        "\n",
        "*   `pasting_classifier_predictions = pasting_classifier.predict(digits_X_val)`:\n",
        "    Makes predictions on the Digits validation set using the Pasting Classifier, with predictions aggregated via voting.\n",
        "\n",
        "*   `accuracy_pasting_classifier = accuracy_score(digits_y_val, pasting_classifier_predictions)`:\n",
        "    Calculates the accuracy of the Pasting Classifier.\n",
        "\n",
        "*   `print(f\"Accuracy of PastingClassifier (Classification): {accuracy_pasting_classifier}\")`\n",
        "    `print(f\"Improvement in Accuracy over DecisionTreeClassifier: {accuracy_pasting_classifier - accuracy_baseline_classifier:.2f}\")`:\n",
        "    Prints the accuracy and improvement over the Decision Tree Classifier baseline.\n",
        "\n",
        "*   `print(f\"Comparison of Accuracy with BaggingClassifier: {accuracy_bagging_classifier - accuracy_pasting_classifier:.2f}\")`:\n",
        "    Prints a comparison of accuracy between Pasting and Bagging Classifiers.\n",
        "\n",
        "*   `print(\"\\nClassification Report for PastingClassifier:\")`\n",
        "    `print(classification_report(digits_y_val, pasting_classifier_predictions))`:\n",
        "    `print(\"\\nConfusion Matrix for PastingClassifier:\")`\n",
        "    `print(confusion_matrix(digits_y_val, pasting_classifier_predictions))`:\n",
        "    Prints the classification report and confusion matrix for the Pasting Classifier.\n",
        "\n",
        "**Plotting (Regression and Classification):**\n",
        "\n",
        "*   **Regression Plot (Actual vs Predicted Prices for PastingRegressor):**\n",
        "    *   Creates a scatter plot for `PastingRegressor` predictions, similar to previous regression plots.\n",
        "\n",
        "*   **Classification Plot (Confusion Matrix for PastingClassifier):**\n",
        "    *   Displays the confusion matrix for `PastingClassifier` as a heatmap, adapted for the Digits dataset.\n",
        "\n",
        "Step 2 implements Pasting for both regression and classification, allowing students to explore the effect of sampling without replacement in ensemble methods. By comparing Pasting to both Decision Tree baselines and Bagging ensembles, students can start to understand the nuances of different ensemble techniques and their relative performance. The focus is on the difference in sampling strategy (without replacement in Pasting vs. with replacement in Bagging) and its impact on model performance."
      ],
      "metadata": {
        "id": "cOdI0eZLkgBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------\n",
        "# Step 3: Random Forests - Regression and Classification\n",
        "#------------------------------------\n",
        "print(\"\\n\\n----- Step 3: Random Forests - Regression and Classification -----\")\n",
        "# Explanation: Create and evaluate Random Forest ensembles for both regression and classification, comparing to Decision Tree, Bagging, and Pasting models.\n",
        "\n",
        "# 3.1 Create and Train RandomForestRegressor\n",
        "forest_regressor = RandomForestRegressor(n_estimators=10, random_state=0)\n",
        "forest_regressor.fit(iowa_X_train, y_train)\n",
        "print(\"\\nRandomForestRegressor model trained successfully!\")\n",
        "\n",
        "# 3.2 Make predictions and evaluate RandomForestRegressor (Regression)\n",
        "forest_regressor_predictions = forest_regressor.predict(iowa_X_val)\n",
        "mae_forest_regressor = mean_absolute_error(y_val, forest_regressor_predictions)\n",
        "mse_forest_regressor = mean_squared_error(y_val, forest_regressor_predictions)\n",
        "print(f\"MAE of RandomForestRegressor (Regression): {mae_forest_regressor}\")\n",
        "print(f\"MSE of RandomForestRegressor (Regression): {mse_forest_regressor}\")\n",
        "print(f\"Improvement in MAE over DecisionTreeRegressor: {mae_baseline_regressor - mae_forest_regressor:.2f}\")\n",
        "print(f\"Improvement in MSE over DecisionTreeRegressor: {mse_baseline_regressor - mse_forest_regressor:.2f}\")\n",
        "print(f\"Comparison of MAE with BaggingRegressor: {mae_bagging_regressor - mae_forest_regressor:.2f}\")\n",
        "print(f\"Comparison of MSE with BaggingRegressor: {mse_bagging_regressor - mse_forest_regressor:.2f}\")\n",
        "print(f\"Comparison of MAE with PastingRegressor: {mae_pasting_regressor - mae_forest_regressor:.2f}\")\n",
        "print(f\"Comparison of MSE with PastingRegressor: {mse_pasting_regressor - mse_forest_regressor:.2f}\")\n",
        "\n",
        "\n",
        "# 3.3 Create and Train RandomForestClassifier\n",
        "forest_classifier = RandomForestClassifier(n_estimators=10, random_state=0)\n",
        "forest_classifier.fit(digits_X_train, digits_y_train)\n",
        "print(\"\\nRandomForestClassifier model trained successfully!\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# 3.4 Make predictions and evaluate RandomForestClassifier (Classification)\n",
        "forest_classifier_predictions = forest_classifier.predict(digits_X_val)\n",
        "accuracy_forest_classifier = accuracy_score(digits_y_val, forest_classifier_predictions)\n",
        "print(f\"Accuracy of RandomForestClassifier (Classification): {accuracy_forest_classifier}\")\n",
        "print(f\"Improvement in Accuracy over DecisionTreeClassifier: {accuracy_forest_classifier - accuracy_baseline_classifier:.2f}\")\n",
        "print(f\"Comparison of Accuracy with BaggingClassifier: {accuracy_bagging_classifier - accuracy_forest_classifier:.2f}\")\n",
        "print(f\"Comparison of Accuracy with PastingClassifier: {accuracy_pasting_classifier - accuracy_forest_classifier:.2f}\")\n",
        "\n",
        "print(\"\\nClassification Report for RandomForestClassifier:\")\n",
        "print(classification_report(digits_y_val, forest_classifier_predictions))\n",
        "print(\"\\nConfusion Matrix for RandomForestClassifier:\")\n",
        "print(confusion_matrix(digits_y_val, forest_classifier_predictions))\n",
        "\n",
        "# Explanation:\n",
        "# We are creating Random Forest ensembles for both regression and classification.\n",
        "# Random Forests are an extension of Bagging that introduces additional\n",
        "# randomness by also selecting random subsets of features when splitting nodes\n",
        "# in the Decision Trees. We train them, make predictions, and evaluate their\n",
        "# performance, comparing against Decision Tree, Bagging, and Pasting models.\n",
        "\n",
        "# 3.5 Plotting Predictions of RandomForestRegressor (Regression)\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(y_val, forest_regressor_predictions, alpha=0.5)\n",
        "plt.xlabel(\"Actual Prices\")\n",
        "plt.ylabel(\"Predicted Prices\")\n",
        "plt.title(\"RandomForestRegressor: Actual vs Predicted (Ensemble Regression Model)\")\n",
        "plt.plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], color='red')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3.6 Plotting Confusion Matrix of RandomForestClassifier (Classification)\n",
        "cm = confusion_matrix(digits_y_val, forest_classifier_predictions)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(digits_y))\n",
        "disp.plot(cmap=plt.cm.Blues) # Use cmap for color scheme\n",
        "plt.title('Confusion Matrix - Decision Tree Classifier (Baseline Classification Model - Digits)') # Updated title\n",
        "plt.xticks(rotation=45) # Rotate x-axis labels for better visibility\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hWOcN3AIhhVu",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explanation of Code Cell for Step 3: Random Forests - Regression and Classification**\n",
        "\n",
        "This code cell implements and evaluates **Random Forest ensembles** for both regression and classification tasks. Random Forests are a highly popular and effective ensemble method that builds upon the concept of Bagging.  They introduce an additional layer of randomness by not only bootstrapping the data but also by randomly selecting a subset of features at each node split in the Decision Trees. This feature randomness further decorrelates the trees in the forest, often leading to improved performance and generalization.\n",
        "\n",
        "**Random Forest Regressor (RandomForestRegressor):**\n",
        "\n",
        "*   `print(\"\\n\\n----- Step 3: Random Forests - Regression and Classification -----\")`: Prints a heading for Step 3, indicating Random Forest models.\n",
        "\n",
        "*   `forest_regressor = RandomForestRegressor(n_estimators=10, random_state=0)`:\n",
        "    Creates a `RandomForestRegressor` object from `sklearn.ensemble`.\n",
        "    *   `RandomForestRegressor(...)`: Initializes a Random Forest Regressor ensemble.\n",
        "    *   `n_estimators=10`: Sets the number of trees in the Random Forest to 10.\n",
        "    *   `random_state=0`: Sets a seed for reproducibility.\n",
        "\n",
        "*   `forest_regressor.fit(iowa_X_train, y_train)`:\n",
        "    Trains the `forest_regressor` ensemble using the Iowa housing training data. This step trains 10 Decision Tree regressors, each on a bootstrapped sample of the data, and with feature randomness applied during tree building.\n",
        "\n",
        "*   `print(\"\\nRandomForestRegressor model trained successfully!\")`: Confirmation message.\n",
        "\n",
        "*   `forest_regressor_predictions = forest_regressor.predict(iowa_X_val)`:\n",
        "    Makes predictions using the trained `forest_regressor` on the Iowa housing validation set. Predictions are averaged across the 10 trees.\n",
        "\n",
        "*   `mae_forest_regressor = mean_absolute_error(y_val, forest_regressor_predictions)`:\n",
        "    `mse_forest_regressor = mean_squared_error(y_val, forest_regressor_predictions)`:\n",
        "    Calculates MAE and MSE for the Random Forest Regressor.\n",
        "\n",
        "*   `print(f\"MAE of RandomForestRegressor (Regression): {mae_forest_regressor}\")`\n",
        "    `print(f\"MSE of RandomForestRegressor (Regression): {mse_forest_regressor}\")`:\n",
        "    Prints the MAE and MSE.\n",
        "\n",
        "*   `print(f\"Improvement in MAE over DecisionTreeRegressor: {mae_baseline_regressor - mae_forest_regressor:.2f}\")`\n",
        "    `print(f\"Improvement in MSE over DecisionTreeRegressor: {mse_baseline_regressor - mse_forest_regressor:.2f}\")`:\n",
        "    Prints the improvement over the Decision Tree Regressor baseline.\n",
        "\n",
        "*   `print(f\"Comparison of MAE with BaggingRegressor: {mae_bagging_regressor - mae_forest_regressor:.2f}\")`\n",
        "    `print(f\"Comparison of MSE with BaggingRegressor: {mse_bagging_regressor - mse_forest_regressor:.2f}\")`:\n",
        "    `print(f\"Comparison of MAE with PastingRegressor: {mae_pasting_regressor - mae_forest_regressor:.2f}\")`\n",
        "    `print(f\"Comparison of MSE with PastingRegressor: {mse_pasting_regressor - mse_forest_regressor:.2f}\")`:\n",
        "    Prints comparisons of MAE and MSE between Random Forest Regressor and both Bagging and Pasting Regressors, allowing for performance comparisons among all three ensemble methods and the Decision Tree baseline.\n",
        "\n",
        "**Random Forest Classifier (RandomForestClassifier):**\n",
        "\n",
        "*   `forest_classifier = RandomForestClassifier(n_estimators=10, random_state=0)`:\n",
        "    Creates a `RandomForestClassifier` object, configured similarly to `RandomForestRegressor` but for classification.\n",
        "\n",
        "*   `forest_classifier.fit(digits_X_train, digits_y_train)`:\n",
        "    Trains the `forest_classifier` ensemble on the Digits training data.\n",
        "\n",
        "*   `print(\"\\nRandomForestClassifier model trained successfully!\")`: Confirmation message.\n",
        "\n",
        "*   `forest_classifier_predictions = forest_classifier.predict(digits_X_val)`:\n",
        "    Makes predictions on the Digits validation set using the Random Forest Classifier, with predictions aggregated via voting.\n",
        "\n",
        "*   `accuracy_forest_classifier = accuracy_score(digits_y_val, forest_classifier_predictions)`:\n",
        "    Calculates the accuracy of the Random Forest Classifier.\n",
        "\n",
        "*   `print(f\"Accuracy of RandomForestClassifier (Classification): {accuracy_forest_classifier}\")`\n",
        "    `print(f\"Improvement in Accuracy over DecisionTreeClassifier: {accuracy_forest_classifier - accuracy_baseline_classifier:.2f}\")`:\n",
        "    Prints the accuracy and improvement over the Decision Tree Classifier baseline.\n",
        "\n",
        "*   `print(f\"Comparison of Accuracy with BaggingClassifier: {accuracy_bagging_classifier - accuracy_forest_classifier:.2f}\")`\n",
        "    `print(f\"Comparison of Accuracy with PastingClassifier: {accuracy_pasting_classifier - accuracy_forest_classifier:.2f}\")`:\n",
        "    Prints comparisons of accuracy between Random Forest Classifier and both Bagging and Pasting Classifiers.\n",
        "\n",
        "*   `print(\"\\nClassification Report for RandomForestClassifier:\")`\n",
        "    `print(classification_report(digits_y_val, forest_classifier_predictions))`:\n",
        "    `print(\"\\nConfusion Matrix for RandomForestClassifier:\")`\n",
        "    `print(confusion_matrix(digits_y_val, forest_classifier_predictions))`:\n",
        "    Prints the classification report and confusion matrix for the Random Forest Classifier.\n",
        "\n",
        "**Plotting (Regression and Classification):**\n",
        "\n",
        "*   **Regression Plot (Actual vs Predicted Prices for RandomForestRegressor):**\n",
        "    *   Creates a scatter plot for `RandomForestRegressor` predictions.\n",
        "\n",
        "*   **Classification Plot (Confusion Matrix for RandomForestClassifier):**\n",
        "    *   Displays the confusion matrix for `RandomForestClassifier` as a heatmap, adapted for the Digits dataset.\n",
        "\n",
        "Step 3 introduces Random Forests, a powerful ensemble technique that combines Bagging with feature randomness. By implementing and evaluating Random Forests for both regression and classification, and comparing their performance to Decision Trees, Bagging, and Pasting, students can appreciate the effectiveness of Random Forests and understand the impact of feature randomness in further improving ensemble performance. This step highlights Random Forests as a state-of-the-art ensemble method and allows for a comprehensive comparison of all ensemble techniques covered so far."
      ],
      "metadata": {
        "id": "2knCNhXAkkVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------\n",
        "# Step 4: Hyperparameter Tuning for Random Forests\n",
        "#------------------------------------\n",
        "print(\"\\n\\n----- Step 4: Hyperparameter Tuning for Random Forests -----\")\n",
        "# Explanation: Explore the impact of key hyperparameters in RandomForestRegressor and RandomForestClassifier.\n",
        "\n",
        "# 4.1 Tuning n_estimators for RandomForestRegressor\n",
        "n_estimators_vals = [10, 50, 100, 200, 500]\n",
        "mae_scores_n_estimators_reg = []\n",
        "for n_est in n_estimators_vals:\n",
        "    rf_reg = RandomForestRegressor(n_estimators=n_est, random_state=0)\n",
        "    rf_reg.fit(iowa_X_train, y_train)\n",
        "    predictions = rf_reg.predict(iowa_X_val)\n",
        "    mae = mean_absolute_error(y_val, predictions)\n",
        "    mae_scores_n_estimators_reg.append(mae)\n",
        "print(\"\\nMAE scores for RandomForestRegressor with different n_estimators:\", mae_scores_n_estimators_reg)\n",
        "\n",
        "# 4.2 Tuning max_depth for RandomForestRegressor\n",
        "max_depth_vals = [None, 5, 10, 15, 20]\n",
        "mae_scores_max_depth_reg = []\n",
        "for max_d in max_depth_vals:\n",
        "    rf_reg = RandomForestRegressor(max_depth=max_d, n_estimators=100, random_state=0) # Fixed n_estimators for this tuning\n",
        "    rf_reg.fit(iowa_X_train, y_train)\n",
        "    predictions = rf_reg.predict(iowa_X_val)\n",
        "    mae = mean_absolute_error(y_val, predictions)\n",
        "    mae_scores_max_depth_reg.append(mae)\n",
        "print(\"\\nMAE scores for RandomForestRegressor with different max_depth:\", mae_scores_max_depth_reg)\n",
        "\n",
        "\n",
        "# 4.3 Tuning n_estimators for RandomForestClassifier\n",
        "n_estimators_vals_clf = [10, 20, 30, 40, 50, 75, 100, 150, 200]\n",
        "accuracy_scores_n_estimators_clf = []\n",
        "for n_est in n_estimators_vals_clf:\n",
        "    rf_clf = RandomForestClassifier(n_estimators=n_est, random_state=0)\n",
        "    rf_clf.fit(digits_X_train, digits_y_train)\n",
        "    predictions = rf_clf.predict(digits_X_val)\n",
        "    accuracy = accuracy_score(digits_y_val, predictions)\n",
        "    accuracy_scores_n_estimators_clf.append(accuracy)\n",
        "print(\"\\nAccuracy scores for RandomForestClassifier with different n_estimators:\", accuracy_scores_n_estimators_clf)\n",
        "\n",
        "# 4.4 Tuning max_depth for RandomForestClassifier\n",
        "max_depth_vals_clf = [None, 5, 10, 15, 20]\n",
        "accuracy_scores_max_depth_clf = []\n",
        "for max_d in max_depth_vals_clf:\n",
        "    rf_clf = RandomForestClassifier(max_depth=max_d, n_estimators=100, random_state=0) # Fixed n_estimators for this tuning\n",
        "    rf_clf.fit(digits_X_train, digits_y_train)\n",
        "    predictions = rf_clf.predict(digits_X_val)\n",
        "    accuracy = accuracy_score(digits_y_val, predictions)\n",
        "    accuracy_scores_max_depth_clf.append(accuracy)\n",
        "print(\"\\nAccuracy scores for RandomForestClassifier with different max_depth:\", accuracy_scores_max_depth_clf)\n",
        "\n",
        "\n",
        "# Explanation:\n",
        "# We are exploring the impact of two key hyperparameters for Random Forests:\n",
        "# - n_estimators: Number of trees in the forest.\n",
        "# - max_depth: Maximum depth of each tree.\n",
        "# We iterate through different values for each hyperparameter, train Random Forest\n",
        "# models, evaluate performance, and print the scores to observe the impact.\n",
        "\n",
        "# 4.5 Plotting n_estimators vs MAE for RandomForestRegressor\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(n_estimators_vals, mae_scores_n_estimators_reg, marker='o')\n",
        "plt.xlabel(\"n_estimators\")\n",
        "plt.ylabel(\"Mean Absolute Error (MAE)\")\n",
        "plt.title(\"RandomForestRegressor: n_estimators vs MAE\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 4.6 Plotting max_depth vs MAE for RandomForestRegressor\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(max_depth_vals, mae_scores_max_depth_reg, marker='o')\n",
        "plt.xlabel(\"max_depth\")\n",
        "plt.ylabel(\"Mean Absolute Error (MAE)\")\n",
        "plt.title(\"RandomForestRegressor: max_depth vs MAE\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 4.7 Plotting n_estimators vs Accuracy for RandomForestClassifier\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(n_estimators_vals_clf, accuracy_scores_n_estimators_clf, marker='o')\n",
        "plt.xlabel(\"n_estimators\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"RandomForestClassifier: n_estimators vs Accuracy (Digits Dataset)\") # Updated title\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 4.8 Plotting max_depth vs Accuracy for RandomForestClassifier\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(max_depth_vals_clf, accuracy_scores_max_depth_clf, marker='o')\n",
        "plt.xlabel(\"max_depth\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"RandomForestClassifier: max_depth vs Accuracy (Digits Dataset)\") # Updated title\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BgIDQRBShku8",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretation of Hyperparameter Tuning Results for Random Forests\n",
        "\n",
        "This section analyzes the performance of Random Forest models (Regressor and Classifier) with varying `n_estimators` and `max_depth` hyperparameters. The goal is to identify optimal settings for improved model accuracy.\n",
        "\n",
        "**Understanding the Output:**\n",
        "\n",
        "The output displays performance scores (MAE for Regressor, Accuracy for Classifier) for different combinations of `n_estimators` (number of trees) and `max_depth` (maximum tree depth).\n",
        "\n",
        "**Interpreting the Scores:**\n",
        "\n",
        "1. **MAE scores for RandomForestRegressor with different n_estimators:**\n",
        "    * These scores represent the Mean Absolute Error (MAE) of the Regressor with varying numbers of trees.\n",
        "    * **Interpretation:** MAE generally decreases as `n_estimators` increases, indicating that more trees improve accuracy. However, improvement might plateau.\n",
        "\n",
        "2. **MAE scores for RandomForestRegressor with different max_depth:**\n",
        "    * These scores show the MAE of the Regressor when varying the maximum depth of the trees.\n",
        "    * **Interpretation:** There isn't a clear trend with increasing `max_depth`. The optimal value balances accuracy and avoids overfitting. `max_depth=None` was included for comparison.\n",
        "\n",
        "3. **Accuracy scores for RandomForestClassifier with different n_estimators:**\n",
        "    * These scores represent the accuracy of the Classifier with different numbers of trees.\n",
        "    * **Interpretation:** Accuracy generally increases with increasing `n_estimators`, but improvement may plateau.\n",
        "\n",
        "4. **Accuracy scores for RandomForestClassifier with different max_depth:**\n",
        "    * These scores show the accuracy of the Classifier when varying the maximum depth of the trees.\n",
        "    * **Interpretation:** There isn't a clear trend with increasing `max_depth`. The optimal value balances accuracy and avoids overfitting. `max_depth=None` was included for comparison.\n"
      ],
      "metadata": {
        "id": "zsF3B6tm4FtE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explanation of Code Cell for Step 4: Hyperparameter Tuning for Random Forests**\n",
        "\n",
        "This code cell focuses on **hyperparameter tuning** for **Random Forest models**. Hyperparameters are settings of a machine learning model that are not learned from the data but are set prior to training. Tuning these hyperparameters is crucial to optimize model performance and generalization. This step explores the impact of two key hyperparameters in Random Forests: `n_estimators` (number of trees in the forest) and `max_depth` (maximum depth of each tree).\n",
        "\n",
        "**Hyperparameter Tuning for RandomForestRegressor:**\n",
        "\n",
        "*   `print(\"\\n\\n----- Step 4: Hyperparameter Tuning for Random Forests -----\")`: Prints a heading for Step 4, indicating hyperparameter tuning.\n",
        "\n",
        "*   **Tuning `n_estimators` for `RandomForestRegressor`:**\n",
        "    *   `n_estimators_vals = [10, 50, 100, 200, 500]`: Defines a list of different values for the `n_estimators` hyperparameter to be tested. These values represent the number of trees that will be in the Random Forest.\n",
        "    *   `mae_scores_n_estimators_reg = []`: Initializes an empty list to store the MAE scores for each `n_estimators` value.\n",
        "    *   `for n_est in n_estimators_vals:`: Starts a loop that iterates through each value in the `n_estimators_vals` list.\n",
        "        *   `rf_reg = RandomForestRegressor(n_estimators=n_est, random_state=0)`: Creates a `RandomForestRegressor` model with the current `n_estimators` value (`n_est`) and a fixed `random_state` for reproducibility.\n",
        "        *   `rf_reg.fit(iowa_X_train, y_train)`: Trains the `RandomForestRegressor` model using the Iowa housing training data.\n",
        "        *   `predictions = rf_reg.predict(iowa_X_val)`: Makes predictions on the Iowa housing validation set using the trained model.\n",
        "        *   `mae = mean_absolute_error(y_val, predictions)`: Calculates the MAE for the current model's predictions.\n",
        "        *   `mae_scores_n_estimators_reg.append(mae)`: Appends the calculated MAE score to the `mae_scores_n_estimators_reg` list.\n",
        "    *   `print(\"\\nMAE scores for RandomForestRegressor with different n_estimators:\", mae_scores_n_estimators_reg)`: After the loop finishes, this line prints the list of MAE scores corresponding to each `n_estimators` value tested.\n",
        "\n",
        "*   **Tuning `max_depth` for `RandomForestRegressor`:**\n",
        "    *   `max_depth_vals = [None, 5, 10, 15, 20]`: Defines a list of different values for the `max_depth` hyperparameter. `None` means no maximum depth limit.\n",
        "    *   `mae_scores_max_depth_reg = []`: Initializes an empty list to store MAE scores for each `max_depth` value.\n",
        "    *   `for max_d in max_depth_vals:`: Starts a loop that iterates through each value in `max_depth_vals`.\n",
        "        *   `rf_reg = RandomForestRegressor(max_depth=max_d, n_estimators=100, random_state=0)`: Creates a `RandomForestRegressor` model with the current `max_depth` value (`max_d`), a *fixed* `n_estimators=100` (to isolate the effect of `max_depth`), and `random_state=0`.\n",
        "        *   The rest of the loop is similar to the `n_estimators` tuning loop: train, predict, calculate MAE, and append to the scores list.\n",
        "    *   `print(\"\\nMAE scores for RandomForestRegressor with different max_depth:\", mae_scores_max_depth_reg)`: Prints the list of MAE scores for each `max_depth` value.\n",
        "\n",
        "**Hyperparameter Tuning for RandomForestClassifier:**\n",
        "\n",
        "*   **Tuning `n_estimators` for `RandomForestClassifier`:**\n",
        "    *   `n_estimators_vals_clf = [10, 50, 100, 200, 500]`: Defines `n_estimators` values to test for the classifier.\n",
        "    *   `accuracy_scores_n_estimators_clf = []`: Initializes a list to store accuracy scores for each `n_estimators` value.\n",
        "    *   The loop structure and operations are similar to the `n_estimators` tuning for `RandomForestRegressor`, but it uses `RandomForestClassifier`, trains on Digits data, and calculates `accuracy_score` instead of MAE.\n",
        "    *   `print(\"\\nAccuracy scores for RandomForestClassifier with different n_estimators:\", accuracy_scores_n_estimators_clf)`: Prints accuracy scores for different `n_estimators`.\n",
        "\n",
        "*   **Tuning `max_depth` for `RandomForestClassifier`:**\n",
        "    *   `max_depth_vals_clf = [None, 5, 10, 15, 20]`: Defines `max_depth` values for the classifier.\n",
        "    *   `accuracy_scores_max_depth_clf = []`: Initializes a list for accuracy scores for each `max_depth`.\n",
        "    *   The loop structure is again similar, but for `RandomForestClassifier` and `max_depth` tuning, using a fixed `n_estimators=100`.\n",
        "    *   `print(\"\\nAccuracy scores for RandomForestClassifier with different max_depth:\", accuracy_scores_max_depth_clf)`: Prints accuracy scores for different `max_depth` values.\n",
        "\n",
        "**Plotting Hyperparameter Tuning Results:**\n",
        "\n",
        "*   **Plots for `RandomForestRegressor`:**\n",
        "    *   **`n_estimators` vs MAE Plot:** Creates a line plot showing how MAE changes as `n_estimators` varies for `RandomForestRegressor`. This plot helps visualize the relationship between the number of trees and regression performance.\n",
        "    *   **`max_depth` vs MAE Plot:** Creates a line plot showing how MAE changes as `max_depth` varies for `RandomForestRegressor`. This visualizes the impact of tree depth on regression performance.\n",
        "\n",
        "*   **Plots for `RandomForestClassifier`:**\n",
        "    *   **`n_estimators` vs Accuracy Plot:** Creates a line plot of accuracy vs. `n_estimators` for `RandomForestClassifier` on the Digits dataset.\n",
        "    *   **`max_depth` vs Accuracy Plot:** Creates a line plot of accuracy vs. `max_depth` for `RandomForestClassifier` on the Digits dataset.\n",
        "\n",
        "In summary, Step 4 systematically explores the impact of `n_estimators` and `max_depth` hyperparameters on the performance of both `RandomForestRegressor` and `RandomForestClassifier`. By iterating through different hyperparameter values, training models, evaluating performance, and visualizing the results, students can understand how these hyperparameters influence model accuracy and complexity. These plots help in making informed decisions about hyperparameter settings for Random Forest models in practice."
      ],
      "metadata": {
        "id": "iENmglAZkoiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------\n",
        "# Step 5: Comparative Analysis and Visualization\n",
        "#------------------------------------\n",
        "print(\"\\n\\n----- Step 5: Comparative Analysis and Visualization -----\")\n",
        "# Explanation: Compare the performance of all models (Decision Tree, Bagging, Pasting, Random Forest) for both regression and classification using metrics and visualizations.\n",
        "\n",
        "# 5.1 Collect MAE and MSE for all Regression Models\n",
        "regression_model_names = [\"Decision Tree\", \"Bagging\", \"Pasting\", \"Random Forest\"]\n",
        "mae_scores_reg = [mae_baseline_regressor, mae_bagging_regressor, mae_pasting_regressor, mae_forest_regressor]\n",
        "mse_scores_reg = [mse_baseline_regressor, mse_bagging_regressor, mse_pasting_regressor, mse_forest_regressor]\n",
        "\n",
        "# Print MAE and MSE values before plotting\n",
        "print(\"\\nRegression Model MAE Scores:\")\n",
        "for model_name, mae_score in zip(regression_model_names, mae_scores_reg):\n",
        "    print(f\"{model_name}: {mae_score:.2f}\")\n",
        "\n",
        "print(\"\\nRegression Model MSE Scores:\")\n",
        "for model_name, mse_score in zip(regression_model_names, mse_scores_reg):\n",
        "    print(f\"{model_name}: {mse_score:.2f}\")\n",
        "\n",
        "\n",
        "# 5.2 Collect Accuracy for all Classification Models\n",
        "classification_model_names = [\"Decision Tree\", \"Bagging\", \"Pasting\", \"Random Forest\"]\n",
        "accuracy_scores_clf = [accuracy_baseline_classifier, accuracy_bagging_classifier, accuracy_pasting_classifier, accuracy_forest_classifier]\n",
        "\n",
        "# Print Accuracy values before plotting\n",
        "print(\"\\nClassification Model Accuracy Scores:\")\n",
        "for model_name, accuracy_score in zip(classification_model_names, accuracy_scores_clf):\n",
        "    print(f\"{model_name}: {accuracy_score:.2f}\")\n",
        "\n",
        "# Explanation: We are collecting the performance metrics from previous steps for easy comparison.\n",
        "\n",
        "# 5.3 Plotting MAE Comparison for Regression Models\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(regression_model_names, mae_scores_reg, color='skyblue')\n",
        "plt.ylabel(\"Mean Absolute Error (MAE)\")\n",
        "plt.title(\"Comparison of MAE for Regression Models\")\n",
        "plt.ylim(min(mae_scores_reg) * 0.9, max(mae_scores_reg) * 1.1) # Adjust y-axis limits for better visualization\n",
        "for i, v in enumerate(mae_scores_reg):\n",
        "    plt.text(i, v + 0.01 * max(mae_scores_reg), f\"{v:.2f}\", ha='center', va='bottom') # Add value labels on bars\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 5.4 Plotting MSE Comparison for Regression Models\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(regression_model_names, mse_scores_reg, color='lightcoral')\n",
        "plt.ylabel(\"Mean Squared Error (MSE)\")\n",
        "plt.title(\"Comparison of MSE for Regression Models\")\n",
        "plt.ylim(min(mse_scores_reg) * 0.9, max(mse_scores_reg) * 1.1) # Adjust y-axis limits for better visualization\n",
        "for i, v in enumerate(mse_scores_reg):\n",
        "    plt.text(i, v + 0.01 * max(mse_scores_reg), f\"{v:.2f}\", ha='center', va='bottom') # Add value labels on bars\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 5.5 Plotting Accuracy Comparison for Classification Models\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(classification_model_names, accuracy_scores_clf, color='lightgreen')\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Comparison of Accuracy for Classification Models (Digits Dataset)\") # Updated title\n",
        "plt.ylim(min(accuracy_scores_clf) * 0.9, max(accuracy_scores_clf) * 1.1) # Adjust y-axis limits for better visualization\n",
        "for i, v in enumerate(accuracy_scores_clf):\n",
        "    plt.text(i, v + 0.01 * max(accuracy_scores_clf), f\"{v:.2f}\", ha='center', va='bottom') # Add value labels on bars\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cd9Yr4PThoCI",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretation of Step 5 Output and Final Conclusion (Revised)\n",
        "\n",
        "This section analyzes the performance of four different machine learning models (Decision Tree, Bagging, Pasting, and Random Forest) on both regression and classification tasks, considering the corrected MSE value for Pasting. Here's a breakdown:\n",
        "\n",
        "### Regression Task (Iowa Housing Dataset):\n",
        "\n",
        "**Performance Metrics:**\n",
        "\n",
        "| Model | MAE | MSE |\n",
        "|---|---|---|\n",
        "| Decision Tree | 27432.52 | 2790012884.63 |\n",
        "| Bagging | 19014.07 | 1249452686.82 |\n",
        "| Pasting | 24434.84 | 1295328430.72 |\n",
        "| Random Forest | 19419.13 | 1220709259.25 |\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- **Bagging and Random Forest still outperform Decision Tree and Pasting** in terms of both MAE and MSE. Lower values indicate better predictive accuracy.\n",
        "- **Bagging** has the lowest MAE (19014.07), suggesting it has the smallest average error in predicting housing prices.\n",
        "- **Random Forest** has the lowest MSE (1220709259.25), indicating it handles larger errors and outliers slightly better.\n",
        "- **Pasting**, with the corrected MSE, now shows a performance closer to Bagging but still not as good as Random Forest.\n",
        "\n",
        "\n",
        "### Classification Task (Digits Dataset):\n",
        "\n",
        "**Performance Metrics:**\n",
        "\n",
        "| Model | Accuracy |\n",
        "|---|---|\n",
        "| Decision Tree | 0.85 |\n",
        "| Bagging | 0.92 |\n",
        "| Pasting | 0.87 |\n",
        "| Random Forest | 0.94 |\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- **Bagging and Random Forest** significantly outperform Decision Tree and Pasting in terms of accuracy. Higher accuracy means better classification performance.\n",
        "- **Random Forest** achieves the highest accuracy (0.94), demonstrating its effectiveness in recognizing patterns for accurate digit classification.\n",
        "\n",
        "\n",
        "## Understanding the Trade-off between Bagging and Random Forest for Regression\n",
        "\n",
        "This section focuses on clarifying the following conclusion about Bagging and Random Forest for regression tasks:\n",
        "\n",
        "**3. For regression, Bagging demonstrates a slight edge with the lowest MAE, while Random Forest provides better handling of outliers and larger errors with a lower MSE. The choice between the two can depend on the specific problem and priorities regarding error types.**\n",
        "\n",
        "### Understanding MAE and MSE:\n",
        "\n",
        "- **MAE (Mean Absolute Error):** The average of the absolute differences between predicted and actual values. It treats all errors equally, regardless of size. A lower MAE means predictions are generally closer to true values.\n",
        "- **MSE (Mean Squared Error):** The average of the squared differences between predicted and actual values. It penalizes larger errors more heavily due to squaring. A lower MSE suggests the model is less prone to large errors but can be sensitive to outliers.\n",
        "\n",
        "### Bagging's Edge with Lower MAE:\n",
        "\n",
        "- Bagging often achieves the lowest MAE, indicating that, on average, its predictions are closer to the actual values compared to Random Forest.\n",
        "- If your priority is minimizing the average prediction error, regardless of occasional larger errors, Bagging might be a good choice.\n",
        "\n",
        "### Random Forest's Advantage with Lower MSE:\n",
        "\n",
        "- Random Forest often achieves the lowest MSE, indicating it's better at avoiding large prediction errors, even if it might have a slightly higher average error (MAE) than Bagging.\n",
        "- The lower MSE suggests Random Forest is more robust to outliers, as it gives them less influence on the overall error metric.\n",
        "\n",
        "### Choice Based on Problem and Priorities:\n",
        "\n",
        "- **Sensitivity to Outliers:** If your dataset has outliers or you are particularly concerned about large prediction errors, Random Forest's lower MSE might make it a better choice.\n",
        "- **Focus on Average Error:** If minimizing the average prediction error is your primary goal, and you are less concerned about occasional larger errors, Bagging's lower MAE might be preferable.\n",
        "- **Business Context:** The best choice also depends on the specific business problem. For example, in some cases, a large prediction error might have more severe consequences than in others.\n",
        "\n",
        "### Conclusion:\n",
        "\n",
        "Based on the corrected output and observations:\n",
        "\n",
        "1. **Ensemble methods (Bagging and Random Forest) remain superior to single Decision Trees** for both regression and classification, reducing overfitting and enhancing overall performance.\n",
        "\n",
        "2. **Random Forest is generally preferred for classification tasks** due to its higher accuracy and robustness, particularly for complex datasets like the Digits dataset.\n",
        "\n",
        "3. **For regression, Bagging demonstrates a slight edge with the lowest MAE**, while Random Forest provides better handling of outliers and larger errors with a lower MSE. The choice between the two can depend on the specific problem and priorities regarding error types.\n",
        "\n",
        "4. **Pasting, with the corrected MSE, performs better than Decision Tree but not as well as Bagging or Random Forest**. It might be considered an alternative but not the primary choice.\n",
        "\n",
        "The choice between Bagging and Random Forest for regression depends on your tolerance for different types of errors and the specific needs of your problem. If you need more consistent predictions with fewer large errors, Random Forest is a good choice. If minimizing the average error is most important, Bagging might be preferred.\n",
        "\n",
        "\n",
        "The key takeaway remains that ensembles, especially Bagging and Random Forest, are powerful tools for improving predictive performance in machine learning. The choice between them depends on the specific task, dataset, and desired trade-offs between error metrics and computational cost."
      ],
      "metadata": {
        "id": "I3i6JLsz8Qbh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explanation of Code Cell for Step 5: Comparative Analysis and Visualization**\n",
        "\n",
        "This code cell performs a **comparative analysis** of all the models implemented in this module: Decision Tree, Bagging, Pasting, and Random Forest, for both regression and classification tasks. It collects the performance metrics calculated in the previous steps and visualizes them using bar plots, allowing for a clear side-by-side comparison of the effectiveness of each method.\n",
        "\n",
        "**Data Collection for Comparison:**\n",
        "\n",
        "*   `print(\"\\n\\n----- Step 5: Comparative Analysis and Visualization -----\")`: Prints a heading for Step 5, indicating comparative analysis.\n",
        "\n",
        "*   **Regression Model Metrics:**\n",
        "    *   `regression_model_names = [\"Decision Tree\", \"Bagging\", \"Pasting\", \"Random Forest\"]`: Defines a list of names for the regression models, which will be used as labels in the plots.\n",
        "    *   `mae_scores_reg = [mae_baseline_regressor, mae_bagging_regressor, mae_pasting_regressor, mae_forest_regressor]`: Collects the MAE scores calculated for each regression model in Steps 0, 1, 2, and 3 into a list.\n",
        "    *   `mse_scores_reg = [mse_baseline_regressor, mse_bagging_regressor, mse_pasting_regressor, mse_forest_regressor]`: Collects the MSE scores for each regression model.\n",
        "\n",
        "*   **Classification Model Metrics:**\n",
        "    *   `classification_model_names = [\"Decision Tree\", \"Bagging\", \"Pasting\", \"Random Forest\"]`: Defines names for classification models.\n",
        "    *   `accuracy_scores_clf = [accuracy_baseline_classifier, accuracy_bagging_classifier, accuracy_pasting_classifier, accuracy_forest_classifier]`: Collects the accuracy scores for each classification model from Steps 0, 1, 2, and 3.\n",
        "\n",
        "*   `# Explanation: We are collecting the performance metrics from previous steps for easy comparison.`: A comment explaining the purpose of this data collection.\n",
        "\n",
        "**Bar Plots for Performance Comparison:**\n",
        "\n",
        "*   **MAE Comparison for Regression Models:**\n",
        "    *   `plt.figure(figsize=(8, 5))`: Creates a figure for the plot with a specified size.\n",
        "    *   `plt.bar(regression_model_names, mae_scores_reg, color='skyblue')`: Creates a bar plot.\n",
        "        *   `regression_model_names`: Provides the x-axis labels (model names).\n",
        "        *   `mae_scores_reg`: Provides the bar heights (MAE values).\n",
        "        *   `color='skyblue'`: Sets the color of the bars.\n",
        "    *   `plt.ylabel(\"Mean Absolute Error (MAE)\")`: Sets the y-axis label.\n",
        "    *   `plt.title(\"Comparison of MAE for Regression Models\")`: Sets the plot title.\n",
        "    *   `plt.ylim(min(mae_scores_reg) * 0.9, max(mae_scores_reg) * 1.1)`: Sets the y-axis limits to provide better visualization, slightly expanding beyond the min and max MAE values.\n",
        "    *   `for i, v in enumerate(mae_scores_reg): ...`:  This loop adds text labels on top of each bar to display the exact MAE value.\n",
        "        *   `plt.text(i, v + 0.01 * max(mae_scores_reg), f\"{v:.2f}\", ha='center', va='bottom')`: Adds a text annotation at the top of each bar (`v`) at position `i` (bar index), formatted to two decimal places.\n",
        "    *   `plt.tight_layout()`: Adjusts plot layout to prevent labels from overlapping.\n",
        "    *   `plt.show()`: Displays the plot.\n",
        "\n",
        "*   **MSE Comparison for Regression Models:**\n",
        "    *   Creates a bar plot for MSE comparison for regression models, similar to the MAE plot but using `mse_scores_reg` and `color='lightcoral'`.\n",
        "\n",
        "*   **Accuracy Comparison for Classification Models:**\n",
        "    *   Creates a bar plot for Accuracy comparison for classification models, using `accuracy_scores_clf`, `classification_model_names`, `color='lightgreen'`, and updating the `plt.title` to indicate \"Digits Dataset\".\n",
        "\n",
        "*   `# Explanation: ...`: A comment explaining the purpose of the bar plots: to visually compare model performance side-by-side.\n",
        "\n",
        "In summary, Step 5 consolidates the performance metrics of all the models and presents them visually using bar plots. These plots provide a direct and easy-to-understand comparison of how Decision Trees, Bagging, Pasting, and Random Forests perform for both regression and classification tasks. By visually comparing MAE, MSE, and Accuracy across different models, students can quickly grasp the relative effectiveness of each method and observe the improvements gained by using ensemble techniques, particularly Random Forests, over single Decision Trees. The value labels on top of the bars enhance the readability and precision of the comparison."
      ],
      "metadata": {
        "id": "F0d_5cPjkssj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sbn\n",
        "#------------------------------------\n",
        "# Step 6: Feature Importance in Random Forests\n",
        "#------------------------------------\n",
        "print(\"\\n\\n----- Step 6: Feature Importance in Random Forests -----\")\n",
        "# Explanation: Explore feature importance provided by Random Forest models for both regression and classification.\n",
        "\n",
        "# 6.1 Feature Importance for RandomForestRegressor\n",
        "feature_importances_reg = forest_regressor.feature_importances_\n",
        "feature_names_reg = iowa_X_train.columns # Get feature names from training data\n",
        "\n",
        "print(\"####################################################################################\",\n",
        "      \"####################################################################################\")\n",
        "reg_models = [baseline_tree_regressor,\n",
        "              #bagging_regressor,\n",
        "              #pasting_regressor,\n",
        "              forest_regressor,\n",
        "              rf_reg]\n",
        "clf_models = [baseline_tree_classifier,\n",
        "              #bagging_classifier,\n",
        "              #pasting_classifier,\n",
        "              forest_classifier,\n",
        "              rf_clf]\n",
        "## Additional - More prectical\n",
        "def plot_importance(model, features, num=15, save=False):\n",
        "    print(\"Feature Importance Section: \",model.__class__.__name__)\n",
        "    feature_imp = pd.DataFrame({\"Value\":model.feature_importances_,\n",
        "                                \"Feature\": features.columns})\n",
        "    plt.figure(figsize=(10,10))\n",
        "    sbn.set(font_scale=1)\n",
        "    sbn.barplot(x=\"Value\", y=\"Feature\",\n",
        "                data=feature_imp.sort_values(by='Value', ascending=False)[0:num])\n",
        "    plt.title(f\"{model.__class__.__name__} Features\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    if save:\n",
        "        plt.savefig(f\"{model.__class__.__name__}importances.png\")\n",
        "\n",
        "for reg_model in reg_models:\n",
        "    plot_importance(reg_model, iowa_X_train)\n",
        "\n",
        "for clf_model in clf_models:\n",
        "    digits_X_train = pd.DataFrame(digits_X_train, columns=[f'feature_{i}' for i in range(digits_X_train.shape[1])])\n",
        "    plot_importance(clf_model, digits_X_train)\n",
        "print(\"####################################################################################\",\n",
        "      \"####################################################################################\")\n",
        "\n",
        "# Print all features before plotting\n",
        "print(\"\\nAll Features for Regression:\")\n",
        "for feature_name in feature_names_reg:\n",
        "    print(feature_name)\n",
        "\n",
        "# Sort feature importances in descending order and get top features\n",
        "indices_reg = np.argsort(feature_importances_reg)[::-1]\n",
        "top_n_features_reg = 10 # Display top N features\n",
        "top_feature_indices_reg = indices_reg[:top_n_features_reg]\n",
        "top_feature_names_reg = [feature_names_reg[i] for i in top_feature_indices_reg]\n",
        "top_feature_importance_values_reg = feature_importances_reg[top_feature_indices_reg]\n",
        "\n",
        "# 6.2 Plotting Feature Importances for RandomForestRegressor\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Feature Importances - RandomForestRegressor (Top 10)\")\n",
        "plt.bar(range(top_n_features_reg), top_feature_importance_values_reg, align=\"center\")\n",
        "plt.xticks(range(top_n_features_reg), top_feature_names_reg, rotation=45, ha='right') # Rotate x-axis labels\n",
        "plt.xlim([-1, top_n_features_reg])\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 6.3 Feature Importance for RandomForestClassifier\n",
        "feature_importances_clf = forest_classifier.feature_importances_\n",
        "feature_names_clf = digits.feature_names # Feature names from Digits dataset (pixels)\n",
        "\n",
        "print('digits.data\\n',digits.data)\n",
        "\n",
        "\n",
        "# Print all features before plotting\n",
        "print(\"\\nAll Features for Classification:\")\n",
        "for i in range(len(feature_names_clf)):\n",
        "    print(f\"pixel_{i}\")  # Print pixel_0, pixel_1, etc.\n",
        "\n",
        "# Sort feature importances in descending order and get top features\n",
        "indices_clf = np.argsort(feature_importances_clf)[::-1]\n",
        "top_n_features_clf = 10 # Display top N features\n",
        "top_feature_indices_clf = indices_clf[:top_n_features_clf]\n",
        "top_feature_names_clf = [f\"pixel{i}\" for i in top_feature_indices_clf] # Pixel names\n",
        "top_feature_importance_values_clf = feature_importances_clf[top_feature_indices_clf]\n",
        "\n",
        "# 6.4 Plotting Feature Importances for RandomForestClassifier\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Feature Importances - RandomForestClassifier (Digits Dataset - Top 10 Pixels)\") # Updated title\n",
        "plt.bar(range(top_n_features_clf), top_feature_importance_values_clf, align=\"center\", color='coral') # Different color for classifier plot\n",
        "plt.xticks(range(top_n_features_clf), top_feature_names_clf, rotation=45, ha='right') # Rotate x-axis labels\n",
        "plt.xlim([-1, top_n_features_clf])\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lBf1s6mChsBH",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explanation of Code Cell for Step 6: Feature Importance in Random Forests**\n",
        "\n",
        "This code cell explores **feature importance** as provided by **Random Forest models**. Feature importance is a valuable tool to understand which features in the dataset are most influential in making predictions. Random Forests, as tree-based models, can naturally estimate feature importances based on how much each feature contributes to reducing impurity (e.g., Gini impurity for classification, variance for regression) across all trees in the forest.\n",
        "\n",
        "**Feature Importance for RandomForestRegressor:**\n",
        "\n",
        "*   `print(\"\\n\\n----- Step 6: Feature Importance in Random Forests -----\")`: Prints a heading for Step 6, indicating feature importance exploration.\n",
        "\n",
        "*   `feature_importances_reg = forest_regressor.feature_importances_`:\n",
        "    Retrieves the feature importances from the already trained `forest_regressor` (RandomForestRegressor model from Step 3).\n",
        "    *   `.feature_importances_`: This attribute of a trained `RandomForestRegressor` (and `RandomForestClassifier`) object stores the feature importances as an array. The importance of each feature is a numerical value, with higher values indicating greater importance.\n",
        "\n",
        "*   `feature_names_reg = iowa_X_train.columns`:\n",
        "    Gets the column names (feature names) from the Iowa housing training data (`iowa_X_train`). These names will be used to label the features in the plot.\n",
        "\n",
        "*   **Sorting and Selecting Top Features (Regression):**\n",
        "    *   `indices_reg = np.argsort(feature_importances_reg)[::-1]`: Sorts the feature importances in descending order and gets the indices.\n",
        "        *   `np.argsort(feature_importances_reg)`: Returns the indices that would sort the `feature_importances_reg` array in ascending order.\n",
        "        *   `[::-1]`: Slices the index array to reverse it, resulting in indices that sort in descending order (from most important to least important).\n",
        "    *   `top_n_features_reg = 10`: Sets the number of top features to display in the plot (top 10 in this case).\n",
        "    *   `top_feature_indices_reg = indices_reg[:top_n_features_reg]`: Selects the indices of the top N features from the sorted indices.\n",
        "    *   `top_feature_names_reg = [feature_names_reg[i] for i in top_feature_indices_reg]`: Gets the names of the top N features using their indices and the `feature_names_reg` list.\n",
        "    *   `top_feature_importance_values_reg = feature_importances_reg[top_feature_indices_reg]`: Gets the importance values of the top N features.\n",
        "\n",
        "*   **Plotting Feature Importances for RandomForestRegressor:**\n",
        "    *   `plt.figure(figsize=(10, 6))`: Creates a figure for the plot.\n",
        "    *   `plt.title(\"Feature Importances - RandomForestRegressor (Top 10)\")`: Sets the plot title.\n",
        "    *   `plt.bar(range(top_n_features_reg), top_feature_importance_values_reg, align=\"center\")`: Creates a bar plot.\n",
        "        *   `range(top_n_features_reg)`: Provides x-axis positions for the bars (0 to 9 for top 10 features).\n",
        "        *   `top_feature_importance_values_reg`: Provides the bar heights (importance values of top features).\n",
        "        *   `align=\"center\"`: Centers the bars on the x-axis ticks.\n",
        "    *   `plt.xticks(range(top_n_features_reg), top_feature_names_reg, rotation=45, ha='right')`: Sets the x-axis tick positions and labels.\n",
        "        *   `range(top_n_features_reg)`: Tick positions.\n",
        "        *   `top_feature_names_reg`: Tick labels (feature names).\n",
        "        *   `rotation=45, ha='right'`: Rotates x-axis labels by 45 degrees and horizontally aligns them to the right for better readability.\n",
        "    *   `plt.xlim([-1, top_n_features_reg])`: Sets x-axis limits.\n",
        "    *   `plt.ylabel(\"Importance\")`: Sets y-axis label.\n",
        "    *   `plt.tight_layout()`: Adjusts layout.\n",
        "    *   `plt.show()`: Displays the plot.\n",
        "\n",
        "**Feature Importance for RandomForestClassifier:**\n",
        "\n",
        "*   `feature_importances_clf = forest_classifier.feature_importances_`:\n",
        "    Retrieves feature importances from the trained `forest_classifier` (RandomForestClassifier).\n",
        "\n",
        "*   `feature_names_clf = digits.feature_names`:\n",
        "    Attempts to get feature names from `digits.feature_names`. For the Digits dataset, `digits.feature_names` is actually `None` because the features are pixel values without meaningful names.\n",
        "\n",
        "*   **Sorting and Selecting Top Features (Classification):**\n",
        "    *   Similar sorting and top feature selection logic as for regression.\n",
        "    *   `top_feature_names_clf = [f\"pixel{i}\" for i in top_feature_indices_clf]`:  Since `digits.feature_names` is `None`, this line creates artificial feature names like \"pixel0\", \"pixel1\", etc., for the top pixel features. This provides meaningful labels for the plot.\n",
        "\n",
        "*   **Plotting Feature Importances for RandomForestClassifier:**\n",
        "    *   Similar plotting logic as for regression, but:\n",
        "        *   `plt.title(\"Feature Importances - RandomForestClassifier (Digits Dataset - Top 10 Pixels)\")`: Updated title to specify Digits dataset and \"Pixels\".\n",
        "        *   `color='coral'`: Uses a different color for the classifier plot.\n",
        "\n",
        "In summary, Step 6 demonstrates how to extract and visualize feature importances from Random Forest models. It shows how to retrieve the `feature_importances_` attribute, sort and select top features, handle feature names (including creating artificial names for pixel features in the Digits dataset), and create bar plots to display the importance of each feature. These plots provide valuable insights into which features are most influential in the models' predictions, aiding in understanding the data and model behavior. This step highlights the interpretability aspect of Random Forests through feature importance analysis."
      ],
      "metadata": {
        "id": "b62sP4Bekwme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Module 6: Ensemble Methods - Homework Assignment\n",
        "\n",
        "**Instructions:** Please answer the following questions to the best of your ability. For coding tasks, you can modify and run the Colab Notebook provided for Module 6. Please submit your answers and code modifications (if any) as instructed by your instructor.\n",
        "\n",
        "---\n",
        "\n",
        "### Conceptual Understanding\n",
        "\n",
        "1.  **Ensemble Learning Principles**\n",
        "\n",
        "    *   Explain in your own words what **ensemble learning** is and why it is often more effective than using a single machine learning model.  Use the \"wisdom of the crowd\" analogy to support your explanation.\n",
        "        * **Answer: Ensemble Learning is a combination of different models. It is more effective than using a single machine learning model because it bases on diverse models' predictions. Like wisdom of the crowd analogy, it brings multiple models together to achieve better prediction.**\n",
        "\n",
        "    *   What are the two main approaches to ensemble learning we discussed in this module in terms of how base learners are trained? Briefly describe **Bagging** (Bootstrap Aggregating) and **Boosting**.  *(Note: While we focused on Bagging-related methods, briefly mentioning Boosting for broader understanding is helpful)*.\n",
        "        * **Answer: Bagging (Bootstrap Aggregating) is an approach that trains multiple models independently at the same time with randomly selected piece of data. It gives the regression problem prediction generally the mean of the models, otherwise for the classification problem prediction it gives the most voted class as the prediction.**\n",
        "        * **Unlike the Bagging, Boosting is an approach that trains multiple models sequentially which provides the next model to fix the errors of the previous model. On the other words, subsequent learner mostly focuses on misclassified observations.**\n",
        "        * *\n",
        "2.  **Bagging vs. Pasting**\n",
        "\n",
        "    *   What is the key difference between **Bagging** and **Pasting** in terms of how they sample the training data to train multiple base learners?\n",
        "    *   * **As I mentioned above, Boosting contains replacement of samples, which leads instances to be repeated inside the training subsets. Meanwhile, Pasting doesn't contain duplicated instances, instead it contains distinct subsets. So, Bagging with bootstrap samples while Pasting without replacement.**\n",
        "    *   In what situations might Bagging be preferred over Pasting, and in what situations might Pasting be preferred over Bagging? Consider factors like dataset size and the goal of variance reduction.\n",
        "    *   * **Boosting is preferred when the dataset is smaller or noisy to avoid the model to learn overly complex patterns of trained data so it decreases the variance by replacing instances. While Pasting is preferred when data is larger to leverage seperate instances efficiently to avoid biases or underfitting.**\n",
        "        * *\n",
        "\n",
        "3.  **Random Forests: Adding Randomness**\n",
        "\n",
        "    *   Explain what a **Random Forest** is and how it builds upon the concept of Bagging. What is the additional source of randomness introduced in Random Forests compared to basic Bagging?\n",
        "    *   * **RandomForest is an ensemble method stemming from Bagging which consists of randomly selected features at each split of decision trees insted of including all features.**\n",
        "\n",
        "    *   Why is this additional randomness (feature randomness) helpful in Random Forests? How does it contribute to improved model performance and generalization?\n",
        "    *   * **Additional/Feature Randomness is helpful in Random Forests because it reduces the correlation between the trees which provide to avoid to heavily rely on a few strong features. So, it reduces varince/overfitting it thereby contributes to improve model performance and generalization.**\n",
        "        * *\n",
        "4.  **Hyperparameters in Random Forests**\n",
        "\n",
        "    *   Name and briefly describe **two** important hyperparameters in Random Forest models (`RandomForestRegressor` and `RandomForestClassifier`) that we experimented with in this module.\n",
        "    *   * **First of all, let's understand what `n_estimators` and `max_depth` mean. n_estimators refers to total number of trees, while max_depth refers to the max length that the trees can have.**\n",
        "\n",
        "    *   Explain in general terms how increasing the value of `n_estimators` and `max_depth` might affect the performance and complexity of a Random Forest model.\n",
        "    *   * **Increasing `n_estimators` generally improves performance and computational complexity but reduces variance. On the other hand, Increasing `max_depth` increases the complexity and captures more complex patterns which can lead to overfitting.**\n",
        "        * *\n",
        "3.  **Random Forest Hyperparameter Tuning: `n_estimators` for Classification**\n",
        "\n",
        "    *   **Task:** Using the Colab Notebook, revisit Step 4 (Hyperparameter Tuning) focusing on `RandomForestClassifier`. Experiment with a wider range of `n_estimators` values than tested in the notebook (e.g., `n_estimators_vals_clf = [10, 20, 30, 40, 50, 75, 100, 150, 200]`).\n",
        "\n",
        "---\n",
        "**Grading:** This homework will be graded based on the completeness and correctness of your answers to the conceptual questions, the successful implementation of the practical exercises, the quality and clarity of your code modifications, and the thoughtfulness and depth of your analysis and discussions."
      ],
      "metadata": {
        "id": "A3yQvlizh7qF"
      }
    }
  ]
}